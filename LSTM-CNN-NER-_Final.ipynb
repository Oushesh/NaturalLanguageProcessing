{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional, Flatten, Conv1D, MaxPooling1D, Masking, Conv2D, MaxPool2D\n",
    "from keras.initializers import RandomUniform\n",
    "import plac\n",
    "import collections\n",
    "import random\n",
    "\n",
    "from keras.utils import plot_model,Progbar\n",
    "\n",
    "import pathlib\n",
    "import cytoolz\n",
    "import numpy\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional, Flatten, Conv1D, MaxPool1D, Masking, Conv2D, MaxPool2D\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "#import cPickle as pickle\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import spacy\n",
    "\n",
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tqdm\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding, Input, RepeatVector\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import text, sequence\n",
    "import numpy as np\n",
    "import io\n",
    "import keras\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15464084149033071271\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 291241984\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 7380962248303043918\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14381572499614755162\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12589508954143041885\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Method to compute the accruarcy. Call predict_labels to get the labels for the dataset\n",
    "def compute_f1(predictions, correct, idx2Label): \n",
    "    label_pred = []    \n",
    "    for sentence in predictions:\n",
    "        label_pred.append([idx2Label[element] for element in sentence])\n",
    "        \n",
    "    label_correct = []    \n",
    "    for sentence in correct:\n",
    "        label_correct.append([idx2Label[element] for element in sentence])\n",
    "            \n",
    "    \n",
    "    #print label_pred\n",
    "    #print label_correct\n",
    "    \n",
    "    prec = compute_precision(label_pred, label_correct)\n",
    "    rec = compute_precision(label_correct, label_pred)\n",
    "    \n",
    "    f1 = 0\n",
    "    if (rec+prec) > 0:\n",
    "        f1 = 2.0 * prec * rec / (prec + rec);\n",
    "        \n",
    "    return prec, rec, f1\n",
    "\n",
    "def compute_precision(guessed_sentences, correct_sentences):\n",
    "    assert(len(guessed_sentences) == len(correct_sentences))\n",
    "    correctCount = 0\n",
    "    count = 0\n",
    "    \n",
    "    \n",
    "    for sentenceIdx in range(len(guessed_sentences)):\n",
    "        guessed = guessed_sentences[sentenceIdx]\n",
    "        correct = correct_sentences[sentenceIdx]\n",
    "        assert(len(guessed) == len(correct))\n",
    "        idx = 0\n",
    "        while idx < len(guessed):\n",
    "            if guessed[idx][0] == 'B': #A new chunk starts\n",
    "                count += 1\n",
    "                \n",
    "                if guessed[idx] == correct[idx]:\n",
    "                    idx += 1\n",
    "                    correctlyFound = True\n",
    "                    \n",
    "                    while idx < len(guessed) and guessed[idx][0] == 'I': #Scan until it no longer starts with I\n",
    "                        if guessed[idx] != correct[idx]:\n",
    "                            correctlyFound = False\n",
    "                        \n",
    "                        idx += 1\n",
    "                    \n",
    "                    if idx < len(guessed):\n",
    "                        if correct[idx][0] == 'I': #The chunk in correct was longer\n",
    "                            correctlyFound = False\n",
    "                        \n",
    "                    \n",
    "                    if correctlyFound:\n",
    "                        correctCount += 1\n",
    "                else:\n",
    "                    idx += 1\n",
    "            else:  \n",
    "                idx += 1\n",
    "    \n",
    "    precision = 0\n",
    "    if count > 0:\n",
    "        print(correctCount)\n",
    "        precision = float(correctCount) / count\n",
    "        \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length_sent=120\n",
    "def get_ner_sentences(filex):\n",
    "    sent_count = 0\n",
    "    with io.open(filex, encoding='utf-8') as fl:\n",
    "        for line in fl:\n",
    "            line = line.strip()\n",
    "            toks = line.split()\n",
    "            #sentence break\n",
    "            if len(toks)<1:\n",
    "                if len(sent)>0:\n",
    "                    sent_count+=1\n",
    "                    if sent_count%1000==0:\n",
    "                        print(sent_count, sent)\n",
    "                    doc = nlp(sent)\n",
    "                    sent= \"\"\n",
    "                    yield doc\n",
    "                    \n",
    "            #sentence start\n",
    "            elif toks[0]==u'-DOCSTART-':\n",
    "                sent=\"\"\n",
    "            else:\n",
    "                sent+=toks[0]+' '    \n",
    "                \n",
    "#train_docs = get_ner_sentences('eng.train')\n",
    "#train_docs = list(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ner_bio(filex):\n",
    "    sent_count = 0\n",
    "    sent = []\n",
    "    with io.open(filex, encoding='utf-8') as fl:\n",
    "        for line in fl:\n",
    "            line = line.strip()\n",
    "            toks = line.split()\n",
    "            #sentence break\n",
    "            if len(toks)<1:\n",
    "                if len(sent)>0:\n",
    "                    sent_count+=1\n",
    "                    if sent_count%100==0:\n",
    "                        print(sent_count, sent)\n",
    "                    res = sent\n",
    "                    sent = []                   \n",
    "                    yield res\n",
    "                    \n",
    "            #sentence start\n",
    "            elif toks[0]==u'-DOCSTART-':\n",
    "                sent=[]\n",
    "            else:\n",
    "                sent.append(toks[3]+' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 88\n"
     ]
    }
   ],
   "source": [
    "filex='eng.train'\n",
    "with io.open(filex, encoding='utf-8') as fl:\n",
    "    text1=fl.read()\n",
    "filex='eng.testb'\n",
    "with io.open(filex, encoding='utf-8') as fl:\n",
    "    text2=fl.read()\n",
    "\n",
    "text = text1+text2\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_hotencode_labels(train_labels, BIO_LABELS, max_length=150, bio=False): \n",
    "    if bio:\n",
    "        LABELS = BIO_LABELS\n",
    "        ent2id = dict(zip(LABELS, np.arange(len(LABELS))))\n",
    "        train_encids = [[ent2id[i] for i in ents_list] for ents_list in train_labels ]\n",
    "    else:\n",
    "        LABELS = list(set([i.split('-')[-1] for i in BIO_LABELS]))\n",
    "        ent2id = dict(zip(LABELS, np.arange(len(LABELS))))\n",
    "        #train_encids = [[ent2id[i] for i in ents_list] for ents_list in train_labels ]\n",
    "        train_encids = [[ent2id[i.split('-')[-1]] for i in ents_list] for ents_list in train_labels ]\n",
    "            \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(np.arange(len(LABELS)).reshape(len(LABELS),1))\n",
    "\n",
    "    Xs = np.zeros((len(train_labels), max_length), dtype='int32')\n",
    "\n",
    "    for i in range(len(train_encids)):\n",
    "        sent=train_encids[i]\n",
    "        for idx, enc in enumerate(sent):\n",
    "            #print(idx)\n",
    "            try:\n",
    "                Xs[i, idx]=enc\n",
    "            except:\n",
    "                print(sent)\n",
    "                \n",
    "    tr = Xs.reshape(Xs.shape[0], Xs.shape[1], 1)\n",
    "    tr_he = np.array([encoder.transform(tr[i,:,:]).toarray() for i in range(tr.shape[0])])\n",
    "    return tr_he, ent2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(vocab):\n",
    "    max_rank = max(lex.rank+1 for lex in vocab if lex.has_vector)\n",
    "    vectors = numpy.ndarray((max_rank+1, vocab.vectors_length), dtype='float32')\n",
    "    for lex in vocab:\n",
    "        if lex.has_vector:\n",
    "            vectors[lex.rank + 1] = lex.vector\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_char_emb_features(docs, max_sentence_length=150, max_word_length=52):\n",
    "    #docs = list(docs)\n",
    "    Xs = numpy.zeros((len(docs), max_sentence_length, max_word_length), dtype='int32')\n",
    "    for i, sentence in enumerate(docs):\n",
    "        j = 0\n",
    "        #print(len(sentence))\n",
    "        for token in sentence:\n",
    "            for char_id, char in enumerate(token.text):\n",
    "                if char_id >= max_word_length:\n",
    "                    break\n",
    "                Xs[i,j,char_id] = char_indices[char]\n",
    "\n",
    "            j += 1\n",
    "    return Xs\n",
    "\n",
    "# 0 = PADDING\n",
    "# 1 = missing vector\n",
    "def get_word_emb_features(docs, max_length):\n",
    "    #docs = list(docs)\n",
    "    Xs = numpy.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, sentence in enumerate(docs):\n",
    "        j = 0\n",
    "        for token in sentence:\n",
    "            #TODO: els add random vector with id=1 vector = np.random.uniform(-0.25, 0.25, len(split)-1)\n",
    "            if token.has_vector and not token.is_punct and not token.is_space:\n",
    "                Xs[i, j] = token.rank + 1\n",
    "                j += 1\n",
    "                if j >= max_length:\n",
    "                    break\n",
    "    return Xs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt\n",
      "train.txt\n",
      "valid.txt\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "urls = {\"https://github.com/Hironsan/anago/blob/master/data/conll2003/en/raw/train.txt\",\n",
    "        \"https://github.com/Hironsan/anago/blob/master/data/conll2003/en/raw/test.txt\",\n",
    "        \"https://github.com/Hironsan/anago/blob/master/data/conll2003/en/raw/valid.txt\"\n",
    "       }\n",
    "\n",
    "for url in urls:\n",
    "    filename = wget.download(url)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['B-PER ', 'I-PER ', 'O ', 'B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "200 ['O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'B-LOC ', 'O ', 'B-LOC ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "300 ['B-LOC ', 'O ']\n",
      "400 ['B-ORG ', 'O ', 'B-LOC ']\n",
      "500 ['O ', 'O ', 'O ', 'O ', 'B-ORG ']\n",
      "600 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "700 ['O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'B-ORG ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'B-ORG ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'B-ORG ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'B-ORG ', 'O ', 'B-LOC ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'B-ORG ', 'I-ORG ', 'O ', 'B-LOC ', 'O ', 'O ']\n",
      "800 ['O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'B-ORG ', 'I-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "900 ['B-PER ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1000 ['O ', 'O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ']\n",
      "1100 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1200 ['O ', 'O ', 'B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1300 ['O ']\n",
      "1400 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ']\n",
      "1500 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1600 ['O ', 'B-MISC ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'B-PER ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1700 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1800 ['B-LOC ', 'O ', 'B-LOC ', 'O ']\n",
      "1900 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "2000 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "2100 ['O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'I-ORG ', 'I-ORG ', 'I-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "2200 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'O ']\n",
      "2300 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "2400 ['O ', 'B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'O ']\n",
      "2500 ['O ', 'B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'O ']\n",
      "2600 ['O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'B-LOC ', 'O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'I-MISC ', 'O ', 'O ']\n",
      "2700 ['O ', 'B-PER ', 'O ']\n",
      "2800 ['O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "2900 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "3000 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "3100 ['B-ORG ', 'I-ORG ', 'O ', 'B-ORG ', 'O ']\n",
      "3200 ['B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ']\n",
      "3300 ['B-ORG ', 'O ', 'B-LOC ']\n",
      "3400 ['B-ORG ', 'I-ORG ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1000 Woman charged over N. Ireland arms find . \n",
      "2000 One of the dead was a civilian passer-by . \n",
      "3000 Chesterfield 21 11 4 6 22 16 37 \n",
      "100 ['O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "200 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "300 ['O ', 'B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "400 ['B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ']\n",
      "500 ['B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ']\n",
      "600 ['B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "700 ['B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ']\n",
      "800 ['B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ']\n",
      "900 ['B-PER ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1000 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1100 ['B-LOC ', 'O ']\n",
      "1200 ['B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1300 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1400 ['B-MISC ', 'I-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1500 ['O ', 'B-LOC ', 'O ', 'O ', 'O ']\n",
      "1600 ['O ', 'B-ORG ', 'I-ORG ', 'I-ORG ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1700 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1800 ['B-LOC ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "1900 ['O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "2000 ['O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "2100 ['B-ORG ', 'O ', 'B-LOC ']\n",
      "2200 ['O ', 'O ', 'B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "2300 ['B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'B-MISC ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'B-PER ', 'I-PER ', 'O ']\n",
      "2400 ['O ', 'B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'O ']\n",
      "2500 ['O ', 'O ']\n",
      "2600 ['O ', 'B-MISC ', 'O ', 'B-MISC ', 'O ']\n",
      "2700 ['B-ORG ', 'I-ORG ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'B-MISC ', 'O ']\n",
      "2800 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "2900 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "3000 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'B-MISC ', 'O ', 'O ']\n",
      "3100 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ']\n",
      "3200 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "3300 ['O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "3400 ['O ', 'O ', 'O ', 'O ']\n",
      "3500 ['O ', 'B-PER ', 'I-PER ', 'O ', 'O ']\n",
      "3600 ['O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ']\n",
      "3700 ['B-ORG ', 'O ', 'B-ORG ', 'O ']\n",
      "3800 ['B-LOC ', 'O ']\n",
      "3900 ['B-ORG ', 'I-ORG ', 'O ', 'B-ORG ', 'I-ORG ', 'O ']\n",
      "4000 ['B-ORG ', 'O ', 'B-ORG ', 'O ']\n",
      "4100 ['B-ORG ', 'I-ORG ', 'O ', 'B-ORG ', 'I-ORG ', 'O ']\n",
      "4200 ['B-ORG ', 'I-ORG ', 'I-ORG ', 'I-ORG ', 'I-ORG ', 'I-ORG ', 'I-ORG ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "4300 ['B-LOC ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ']\n",
      "4400 ['O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'O ']\n",
      "4500 ['O ', 'O ']\n",
      "4600 ['O ', 'B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'B-ORG ']\n",
      "4700 ['O ', 'O ', 'O ', 'O ']\n",
      "4800 ['O ', 'B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'B-MISC ', 'I-MISC ', 'O ']\n",
      "4900 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "5000 ['B-PER ', 'I-PER ', 'O ', 'O ', 'O ']\n",
      "5100 ['O ', 'O ', 'O ', 'O ', 'B-MISC ']\n",
      "5200 ['B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "5300 ['O ', 'O ', 'O ']\n",
      "5400 ['B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'I-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "5500 ['O ', 'O ', 'B-MISC ', 'O ', 'O ']\n",
      "5600 ['O ', 'B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ']\n",
      "5700 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "5800 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "5900 ['B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "6000 ['B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "6100 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "6200 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "6300 ['B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'O ']\n",
      "6400 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "6500 ['O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ']\n",
      "6600 ['B-LOC ', 'O ', 'O ', 'O ', 'O ']\n",
      "6700 ['O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "6800 ['B-ORG ', 'I-ORG ', 'I-ORG ', 'O ', 'B-ORG ', 'O ']\n",
      "6900 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "7000 ['O ', 'B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "7100 ['B-ORG ', 'O ', 'O ', 'O ', 'O ']\n",
      "7200 ['B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ']\n",
      "7300 ['O ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "7400 ['O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "7500 ['O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'I-ORG ', 'I-ORG ', 'I-ORG ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ']\n",
      "7600 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "7700 ['B-PER ', 'I-PER ', 'O ']\n",
      "7800 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "7900 ['O ', 'B-ORG ', 'I-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "8000 ['O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ']\n",
      "8100 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ']\n",
      "8200 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "8300 ['O ', 'O ', 'B-LOC ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ']\n",
      "8400 ['O ', 'O ', 'O ']\n",
      "8500 ['B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ']\n",
      "8600 ['O ', 'O ', 'B-MISC ', 'I-MISC ', 'I-MISC ', 'O ']\n",
      "8700 ['B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "8800 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'B-ORG ', 'I-ORG ', 'I-ORG ', 'O ']\n",
      "8900 ['O ', 'B-ORG ', 'I-ORG ', 'I-ORG ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "9000 ['O ', 'B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "9100 ['B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ']\n",
      "9200 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "9300 ['O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'B-LOC ', 'O ']\n",
      "9400 ['O ', 'O ', 'B-ORG ', 'O ', 'B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "9500 ['O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "9600 ['O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "9700 ['B-LOC ', 'O ']\n",
      "9800 ['B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ']\n",
      "9900 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'O ']\n",
      "10000 ['O ', 'O ', 'O ', 'O ', 'O ']\n",
      "10100 ['O ', 'B-LOC ', 'O ', 'O ']\n",
      "10200 ['B-LOC ', 'O ']\n",
      "10300 ['B-ORG ', 'O ', 'B-LOC ', 'O ', 'O ', 'B-ORG ', 'O ', 'B-LOC ', 'O ', 'O ', 'B-ORG ', 'O ', 'B-LOC ', 'O ', 'O ', 'B-ORG ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "10400 ['B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'I-PER ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ']\n",
      "10500 ['B-ORG ', 'O ', 'B-ORG ', 'O ']\n",
      "10600 ['O ', 'O ', 'O ', 'O ', 'O ']\n",
      "10700 ['O ', 'O ', 'O ']\n",
      "10800 ['B-ORG ', 'I-ORG ', 'O ', 'B-ORG ', 'O ']\n",
      "10900 ['O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "11000 ['B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11100 ['O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "11200 ['O ', 'B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "11300 ['O ', 'B-MISC ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'I-ORG ', 'I-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "11400 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "11500 ['O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ']\n",
      "11600 ['B-LOC ', 'O ', 'B-LOC ', 'O ']\n",
      "11700 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "11800 ['O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'O ']\n",
      "11900 ['B-ORG ', 'I-ORG ']\n",
      "12000 ['B-ORG ', 'O ', 'B-PER ', 'O ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ']\n",
      "12100 ['O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ']\n",
      "12200 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "12300 ['B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "12400 ['B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'B-PER ', 'I-PER ', 'O ']\n",
      "12500 ['B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "12600 ['B-ORG ', 'O ', 'B-ORG ', 'O ']\n",
      "12700 ['O ', 'B-MISC ', 'O ', 'O ', 'O ', 'B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "12800 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "12900 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "13000 ['O ', 'O ', 'B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "13100 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-PER ', 'I-PER ', 'O ']\n",
      "13200 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'B-LOC ', 'O ']\n",
      "13300 ['B-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "13400 ['O ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "13500 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "13600 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "13700 ['O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "13800 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-ORG ', 'I-ORG ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ']\n",
      "13900 ['O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'O ', 'B-LOC ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'O ', 'B-MISC ', 'O ', 'B-MISC ', 'O ', 'O ', 'O ']\n",
      "14000 ['O ', 'O ', 'O ', 'B-LOC ', 'I-LOC ', 'O ', 'O ', 'B-MISC ', 'I-MISC ', 'O ']\n",
      "1000 The youth side replied with 246 for seven . \n",
      "2000 Unseeded Patrick Rafter recorded the most noteworthy result as he upset sixth-seeded American MaliVai Washington 6-2 6-1 in just 50 minutes . \n",
      "3000 Their release has been negotiated by Islamist writer Ismail Nacar as part of a wider effort , partly backed by Prime Minister Necmettin Erbakan , to find a political solution to Turkey 's Kurdish problem . \n",
      "4000 Lille 3 Rennes 1 \n",
      "5000 Waqar Younis not out 0 \n",
      "6000 Thai army commanders reject the explanation , saying they have evidence the Burmese army supplies and directs the renegade ethnic minority splinter faction . \n",
      "7000 But Stich did n't want to play that game . \n",
      "8000 - Fears of an Israeli operation causes the redistribution of Syrian troops locations in Lebanon . \n",
      "9000 But Meri , 67 , has been accused in parliament of taking too much power and not always consulting parliamentarians before making decisions . \n",
      "10000 Men 's 3,000 metres : \n",
      "11000 Austrian composer and organist , he wrote nine symphonies on a huge scale and three grand masses in the romantic tradition . \n",
      "12000 MOF 's Kubo says believes BOJ rate policy unchanged . \n",
      "13000 The tabloid Star magazine reported the married Morris had a lengthy affair with a $ 200-an-hour prostitute who he allowed to eavesdrop on telephone conversations with Clinton , and with whom he shared White House speeches before they were made . \n",
      "14000 for Sunday 's San Marino 500cc motorcycling Grand Prix : \n"
     ]
    }
   ],
   "source": [
    "#file_str = 'eng.testa'\n",
    "def create_matrices(file_str):\n",
    "    max_sent_length = 150  \n",
    "    doc_labels = list(get_ner_bio(file_str))\n",
    "    BIO_LABELS = list(set([i for sub_list in doc_labels for i in sub_list]))\n",
    "    #print(BIO_LABELS)\n",
    "    LABELS = list(set([i.split('-')[-1] for i in BIO_LABELS]))\n",
    "    doc_labels, ent2id = pad_hotencode_labels(doc_labels, BIO_LABELS, max_length=max_sent_length, bio=True)\n",
    "    \n",
    "    #Memory is not an issue\n",
    "    docs = list(get_ner_sentences(file_str))\n",
    "    word_X = get_word_emb_features(docs, max_sent_length)\n",
    "    char_X = get_char_emb_features(docs)\n",
    "    \n",
    "    doc_labels = np.argmax(doc_labels, axis=2).reshape((len(doc_labels), max_sent_length, 1))\n",
    "    return word_X, char_X, doc_labels, LABELS, ent2id\n",
    "\n",
    "trainF = \"train.txt\"\n",
    "devF = \"test.txt\"\n",
    "testF = \"valid.txt\" #Be careful RAW Dataset\n",
    "\n",
    "dev_word, dev_char, dev_labels, LABELS, ent2id = create_matrices(devF)\n",
    "train_word, train_char, train_labels, LABELS, ent2id = create_matrices(trainF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14041, 150, 1), (14041, 150), (14041, 150, 52))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape, train_word.shape, train_char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save train_labels, train_word, train_char\n",
    "np.save('train_labels.npy',train_labels)\n",
    "np.save('train_word.npy',train_word)\n",
    "np.save('train_char.npy',train_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-ORG ',\n",
       " 1: 'B-PER ',\n",
       " 2: 'I-MISC ',\n",
       " 3: 'I-PER ',\n",
       " 4: 'I-ORG ',\n",
       " 5: 'B-LOC ',\n",
       " 6: 'I-LOC ',\n",
       " 7: 'O ',\n",
       " 8: 'B-MISC '}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2ent = dict((v, k) for k, v in ent2id.items())\n",
    "id2ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-PER '"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2ent[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-LOC ': 5,\n",
       " 'B-MISC ': 8,\n",
       " 'B-ORG ': 0,\n",
       " 'B-PER ': 1,\n",
       " 'I-LOC ': 6,\n",
       " 'I-MISC ': 2,\n",
       " 'I-ORG ': 4,\n",
       " 'I-PER ': 3,\n",
       " 'O ': 7}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sent_batches(train_word, train_char, train_labels):\n",
    "    wx = pd.DataFrame(train_word)\n",
    "    wx['sent_len'] = (wx>0).sum(axis=1)\n",
    "#     sent_lens = (train_word>0).sum(axis=1)\n",
    "    for sent_len, group in wx.groupby('sent_len'):\n",
    "        if sent_len>0:\n",
    "            batch_word = group.drop('sent_len',axis=1).values[:, 0:sent_len]\n",
    "            batch_char = train_char[group.index][:, 0:sent_len,:]\n",
    "            batch_labels = train_labels[group.index][:, 0:sent_len]\n",
    "            #model.train_on_batch([batch_word, batch_char], batch_labels)\n",
    "            #print(sent_len, batch_word.shape, batch_char.shape, batch_labels.shape)\n",
    "            yield (batch_word, batch_char, batch_labels)\n",
    "            \n",
    "train_batches = (get_sent_batches(train_word, train_char, train_labels))\n",
    "dev_batches = (get_sent_batches(dev_word, dev_char, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 14041)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_batches)),len(list(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703 173\n"
     ]
    }
   ],
   "source": [
    "#Needed is train_steps\n",
    "batch_size=20\n",
    "train_steps = int((len(train_labels) - 1) / batch_size) + 1\n",
    "dev_steps =   int((len(dev_labels) - 1) / batch_size) + 1\n",
    "print (train_steps,dev_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#insert the ChainCRF here\n",
    "from __future__ import absolute_import\n",
    "\"\"\"\n",
    "Adapted from: https://github.com/phipleg/keras/blob/crf/keras/layers/crf.py\n",
    "\"\"\"\n",
    "from keras import backend as K\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.engine import Layer, InputSpec\n",
    "\n",
    "def path_energy(y, x, U, b_start=None, b_end=None, mask=None):\n",
    "    x = add_boundary_energy(x, b_start, b_end, mask)\n",
    "    return path_energy0(y, x, U, mask)\n",
    "\n",
    "def path_energy0(y, x, U, mask=None):\n",
    "    n_classes = K.shape(x)[2]\n",
    "    y_one_hot = K.one_hot(y, n_classes)\n",
    "\n",
    "    # Tag path energy\n",
    "    energy = K.sum(x * y_one_hot, 2)\n",
    "    energy = K.sum(energy, 1)\n",
    "\n",
    "    # Transition energy\n",
    "    y_t = y[:, :-1]\n",
    "    y_tp1 = y[:, 1:]\n",
    "    U_flat = K.reshape(U, [-1])\n",
    "    # Convert 2-dim indices (y_t, y_tp1) of U to 1-dim indices of U_flat:\n",
    "    flat_indices = y_t * n_classes + y_tp1\n",
    "    U_y_t_tp1 = K.gather(U_flat, flat_indices)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = K.cast(mask, K.floatx())\n",
    "        y_t_mask = mask[:, :-1]\n",
    "        y_tp1_mask = mask[:, 1:]\n",
    "        U_y_t_tp1 *= y_t_mask * y_tp1_mask\n",
    "\n",
    "    energy += K.sum(U_y_t_tp1, axis=1)\n",
    "\n",
    "    return energy\n",
    "\n",
    "\n",
    "def sparse_chain_crf_loss(y, x, U, b_start=None, b_end=None, mask=None):\n",
    "    x = add_boundary_energy(x, b_start, b_end, mask)\n",
    "    energy = path_energy0(y, x, U, mask)\n",
    "    energy -= free_energy0(x, U, mask)\n",
    "    return K.expand_dims(-energy, -1)\n",
    "\n",
    "def chain_crf_loss(y, x, U, b_start=None, b_end=None, mask=None):\n",
    "    y_sparse = K.argmax(y, -1)\n",
    "    y_sparse = K.cast(y_sparse, 'int32')\n",
    "    return sparse_chain_crf_loss(y_sparse, x, U, b_start, b_end, mask)\n",
    "\n",
    "\n",
    "def add_boundary_energy(x, b_start=None, b_end=None, mask=None):\n",
    "    if mask is None:\n",
    "        if b_start is not None:\n",
    "            x = K.concatenate([x[:, :1, :] + b_start, x[:, 1:, :]], axis=1)\n",
    "        if b_end is not None:\n",
    "            x = K.concatenate([x[:, :-1, :], x[:, -1:, :] + b_end], axis=1)\n",
    "    else:\n",
    "        mask = K.cast(mask, K.floatx())\n",
    "        mask = K.expand_dims(mask, 2)\n",
    "        x *= mask\n",
    "        if b_start is not None:\n",
    "            mask_r = K.concatenate([K.zeros_like(mask[:, :1]), mask[:, :-1]], axis=1)\n",
    "            start_mask = K.cast(K.greater(mask, mask_r), K.floatx())\n",
    "            x = x + start_mask * b_start\n",
    "        if b_end is not None:\n",
    "            mask_l = K.concatenate([mask[:, 1:], K.zeros_like(mask[:, -1:])], axis=1)\n",
    "            end_mask = K.cast(K.greater(mask, mask_l), K.floatx())\n",
    "            x = x + end_mask * b_end\n",
    "    return x\n",
    "\n",
    "\n",
    "def viterbi_decode(x, U, b_start=None, b_end=None, mask=None):\n",
    "    x = add_boundary_energy(x, b_start, b_end, mask)\n",
    "\n",
    "    alpha_0 = x[:, 0, :]\n",
    "    gamma_0 = K.zeros_like(alpha_0)\n",
    "    initial_states = [gamma_0, alpha_0]\n",
    "    _, gamma = _forward(x,\n",
    "                        lambda B: [K.cast(K.argmax(B, axis=1), K.floatx()), K.max(B, axis=1)],\n",
    "                        initial_states,\n",
    "                        U,\n",
    "                        mask)\n",
    "    y = _backward(gamma, mask)\n",
    "    return y\n",
    "\n",
    "\n",
    "def free_energy(x, U, b_start=None, b_end=None, mask=None):\n",
    "    \"\"\"Computes efficiently the sum of all path energies for input x, when\n",
    "    runs over all possible tag sequences.\"\"\"\n",
    "    x = add_boundary_energy(x, b_start, b_end, mask)\n",
    "    return free_energy0(x, U, mask)\n",
    "\n",
    "\n",
    "def free_energy0(x, U, mask=None):\n",
    "    \"\"\"Free energy without boundary potential handling.\"\"\"\n",
    "    initial_states = [x[:, 0, :]]\n",
    "    last_alpha, _ = _forward(x,\n",
    "                             lambda B: [K.logsumexp(B, axis=1)],\n",
    "                             initial_states,\n",
    "                             U,\n",
    "                             mask)\n",
    "    return last_alpha[:, 0]\n",
    "\n",
    "\n",
    "def _forward(x, reduce_step, initial_states, U, mask=None):\n",
    "    def _forward_step(energy_matrix_t, states):\n",
    "        alpha_tm1 = states[-1]\n",
    "        new_states = reduce_step(K.expand_dims(alpha_tm1, 2) + energy_matrix_t)\n",
    "        return new_states[0], new_states\n",
    "\n",
    "    U_shared = K.expand_dims(K.expand_dims(U, 0), 0)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = K.cast(mask, K.floatx())\n",
    "        mask_U = K.expand_dims(K.expand_dims(mask[:, :-1] * mask[:, 1:], 2), 3)\n",
    "        U_shared = U_shared * mask_U\n",
    "\n",
    "    inputs = K.expand_dims(x[:, 1:, :], 2) + U_shared\n",
    "    inputs = K.concatenate([inputs, K.zeros_like(inputs[:, -1:, :, :])], axis=1)\n",
    "\n",
    "    last, values, _ = K.rnn(_forward_step, inputs, initial_states)\n",
    "    return last, values\n",
    "\n",
    "def batch_gather(reference, indices):\n",
    "    ref_shape = K.shape(reference)\n",
    "    batch_size = ref_shape[0]\n",
    "    n_classes = ref_shape[1]\n",
    "    flat_indices = K.arange(0, batch_size) * n_classes + K.flatten(indices)\n",
    "    return K.gather(K.flatten(reference), flat_indices)\n",
    "\n",
    "def _backward(gamma, mask):\n",
    "    gamma = K.cast(gamma, 'int32')\n",
    "\n",
    "    def _backward_step(gamma_t, states):\n",
    "        y_tm1 = K.squeeze(states[0], 0)\n",
    "        y_t = batch_gather(gamma_t, y_tm1)\n",
    "        return y_t, [K.expand_dims(y_t, 0)]\n",
    "\n",
    "    initial_states = [K.expand_dims(K.zeros_like(gamma[:, 0, 0]), 0)]\n",
    "    _, y_rev, _ = K.rnn(_backward_step,\n",
    "                        gamma,\n",
    "                        initial_states,\n",
    "                        go_backwards=True)\n",
    "    y = K.reverse(y_rev, 1)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = K.cast(mask, dtype='int32')\n",
    "        # mask output\n",
    "        y *= mask\n",
    "        # set masked values to -1\n",
    "        y += -(1 - mask)\n",
    "    return y\n",
    "\n",
    "class ChainCRF(Layer):\n",
    "    def __init__(self, init='glorot_uniform',\n",
    "                 U_regularizer=None,\n",
    "                 b_start_regularizer=None,\n",
    "                 b_end_regularizer=None,\n",
    "                 U_constraint=None,\n",
    "                 b_start_constraint=None,\n",
    "                 b_end_constraint=None,\n",
    "                 weights=None,\n",
    "                 **kwargs):\n",
    "        super(ChainCRF, self).__init__(**kwargs)\n",
    "        self.init = initializers.get(init)\n",
    "        self.U_regularizer = regularizers.get(U_regularizer)\n",
    "        self.b_start_regularizer = regularizers.get(b_start_regularizer)\n",
    "        self.b_end_regularizer = regularizers.get(b_end_regularizer)\n",
    "        self.U_constraint = constraints.get(U_constraint)\n",
    "        self.b_start_constraint = constraints.get(b_start_constraint)\n",
    "        self.b_end_constraint = constraints.get(b_end_constraint)\n",
    "\n",
    "        self.initial_weights = weights\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.uses_learning_phase = True\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 3\n",
    "        return (input_shape[0], input_shape[1], input_shape[2])\n",
    "\n",
    "    def compute_mask(self, input, mask=None):\n",
    "        if mask is not None:\n",
    "            return K.any(mask, axis=1)\n",
    "        return mask\n",
    "\n",
    "    def _fetch_mask(self):\n",
    "        mask = None\n",
    "        if self._inbound_nodes:\n",
    "            mask = self._inbound_nodes[0].input_masks[0]\n",
    "        return mask\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        n_classes = input_shape[2]\n",
    "        n_steps = input_shape[1]\n",
    "        assert n_steps is None or n_steps >= 2\n",
    "        self.input_spec = [InputSpec(dtype=K.floatx(),\n",
    "                                     shape=(None, n_steps, n_classes))]\n",
    "\n",
    "        self.U = self.add_weight((n_classes, n_classes),\n",
    "                                 initializer=self.init,\n",
    "                                 name='U',\n",
    "                                 regularizer=self.U_regularizer,\n",
    "                                 constraint=self.U_constraint)\n",
    "\n",
    "        self.b_start = self.add_weight((n_classes, ),\n",
    "                                       initializer='zero',\n",
    "                                       name='b_start',\n",
    "                                       regularizer=self.b_start_regularizer,\n",
    "                                       constraint=self.b_start_constraint)\n",
    "\n",
    "        self.b_end = self.add_weight((n_classes, ),\n",
    "                                     initializer='zero',\n",
    "                                     name='b_end',\n",
    "                                     regularizer=self.b_end_regularizer,\n",
    "                                     constraint=self.b_end_constraint)\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        y_pred = viterbi_decode(x, self.U, self.b_start, self.b_end, mask)\n",
    "        nb_classes = self.input_spec[0].shape[2]\n",
    "        y_pred_one_hot = K.one_hot(y_pred, nb_classes)\n",
    "        return K.in_train_phase(x, y_pred_one_hot)\n",
    "\n",
    "    def loss(self, y_true, y_pred):\n",
    "        \"\"\"Linear Chain Conditional Random Field loss function.\n",
    "        \"\"\"\n",
    "        mask = self._fetch_mask()\n",
    "        return chain_crf_loss(y_true, y_pred, self.U, self.b_start, self.b_end, mask)\n",
    "\n",
    "    def sparse_loss(self, y_true, y_pred):\n",
    "        \"\"\"Linear Chain Conditional Random Field loss function with sparse\n",
    "        tag sequences.\n",
    "        \"\"\"\n",
    "        y_true = K.cast(y_true, 'int32')\n",
    "        y_true = K.squeeze(y_true, 2)\n",
    "        mask = self._fetch_mask()\n",
    "        return sparse_chain_crf_loss(y_true, y_pred, self.U, self.b_start, self.b_end, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 100 8800        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, 52, 100 0           char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, None, 52, 30) 9030        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, None, 1, 30)  0           time_distributed_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, None, 30)     0           time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, None, 300)    205447500   words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, None, 30)     0           time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, None, 330)    0           embedding_13[0][0]               \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, None, 400)    849600      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, None, 100)    40100       bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, None, 9)      909         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "chain_crf_7 (ChainCRF)          (None, None, 9)      99          dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 206,356,038\n",
      "Trainable params: 908,538\n",
      "Non-trainable params: 205,447,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from layers import ChainCRF\n",
    "from keras.optimizers import Nadam\n",
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    word_embeddings = get_embeddings(nlp.vocab)\n",
    "    words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
    "    words = Embedding(input_dim=word_embeddings.shape[0], \n",
    "                      output_dim=word_embeddings.shape[1], \n",
    "                      weights=[word_embeddings], \n",
    "                      trainable=False)(words_input)\n",
    "\n",
    "    #output of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim).\n",
    "    character_input=Input(shape=(None,52,),name='char_input')\n",
    "    embed_char_out=TimeDistributed(Embedding(len(char_indices),100,\n",
    "                                             embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), #maybe change from 0 to 1\n",
    "                                             name='char_embedding')(character_input)\n",
    "\n",
    "    dropout= Dropout(0.5)(embed_char_out)\n",
    "    conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1))(dropout) #extra convolutional Network\n",
    "    maxpool_out=TimeDistributed(MaxPooling1D(52))(conv1d_out)\n",
    "    char = TimeDistributed(Flatten())(maxpool_out)\n",
    "    char = Dropout(0.5)(char)\n",
    "    output = keras.layers.concatenate([words, char]) #concatenation of words and chars to char_embeddings\n",
    "    context_rep = Bidirectional(LSTM(2*100, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output)\n",
    "    #ntime_steps = tf.shape(context_rep)[1]\n",
    "    #len(ent2id)=9\n",
    "    output = Dense(100, activation='softmax')(context_rep)\n",
    "    output = Dense(9)(output)\n",
    "\n",
    "    #output = TimeDistributed(Dense(9, activation='softmax'))(context_rep)\n",
    "\n",
    "    #Add Chain CRF Layer here:\n",
    "    crf=ChainCRF()\n",
    "    pred=crf(output)\n",
    "\n",
    "    #Concatenate both inputs together\n",
    "    #sequence_lengths = Input(batch_shape=(None, 1), dtype='int32')\n",
    "    model = Model(inputs=[words_input, character_input], outputs=[pred]) #accepts 1 Batch at a time\n",
    "    model.compile(loss=crf.loss,optimizer=Nadam(lr=0.001),metrics=['accuracy'])\n",
    "    #model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(lr=0.001), metrics=['categorical_accuracy'])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(9)])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shapes of array\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(9)])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batches = (([i,j],k) for i,j,k in train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctLabels=[]\n",
    "predLabels = []\n",
    "class Metrics(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        prediction = model.predict([train_word,train_char]).flatten()\n",
    "        prediction = np.argmax(prediction, -1)\n",
    "        predLabels.append(prediction)\n",
    "        correctLabels.append(train_labels.reshape(train_labels.shape[0],train_labels.shape[1]).flatten())\n",
    "        f1s=compute_f1(predLabels, correctLabels, id2ent) #id2ent=ids to entity \n",
    "        return f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "14041/14041 [==============================] - 111s 8ms/step - loss: 54.3437 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85b49c7160>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implemeent Callback here\n",
    "model.fit([train_word, train_char], train_labels,batch_size=100, epochs=1)#,callbacks=[metrics])#callbacks=[metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "14041/14041 [==============================] - 419s 30ms/step - loss: 14.5710 - acc: 1.0000\n",
      "Epoch 2/4\n",
      "14041/14041 [==============================] - 419s 30ms/step - loss: 3.6688 - acc: 1.0000\n",
      "Epoch 3/4\n",
      "14041/14041 [==============================] - 418s 30ms/step - loss: 1.7202 - acc: 1.0000\n",
      "Epoch 4/4\n",
      "14041/14041 [==============================] - 418s 30ms/step - loss: 0.9729 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85b49c79b0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with F1 Callback\n",
    "#f1_callback = F1Callback()\n",
    "model.fit([train_word, train_char], train_labels,batch_size=20, epochs=4) #callbacks=[f1_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       ..., \n",
       "       [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]]], dtype=float32)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([dev_word,dev_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_p=model.predict([dev_word,dev_char])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " val_f1: 1.0  val_precision: 1.0  val_recall 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "val_f1s = []\n",
    "val_recalls = []\n",
    "val_precisions = []\n",
    "clasf_report = []\n",
    "\n",
    "y_pred = np.argmax(y_p, axis=-1).flatten('C')\n",
    "y_t = dev_labels\n",
    "y_true = np.argmax(y_t, axis=-1).flatten('C')\n",
    "_val_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "_val_recall = recall_score(y_true, y_pred, average='weighted')\n",
    "_val_precision = precision_score(y_true, y_pred, average='weighted')\n",
    "_clasf_report = classification_report(y_true, y_pred)\n",
    "val_f1s.append(_val_f1)\n",
    "val_recalls.append(_val_recall)\n",
    "val_precisions.append(_val_precision)\n",
    "clasf_report.append(_clasf_report)\n",
    "print(\"\\n val_f1: {}  val_precision: {}  val_recall {}\".format(_val_f1, _val_precision, _val_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = (([i,j],k) for i,j,k in train_batches)\n",
    "dev_generator = (([i,j],k) for i,j,k in dev_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load numpy arrays here:\n",
    "train_labels = np.load('train_labels.npy')\n",
    "train_word = np.load('train_word.npy')\n",
    "train_char = np.load('train_char.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2106150,52,100]\n\t [[Node: char_embedding_6/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](char_embedding_6/embeddings/read, char_embedding_6/Cast)]]\n\t [[Node: chain_crf_7/strided_slice_10/_1869 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5435_chain_crf_7/strided_slice_10\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'char_embedding_6/Gather', defined at:\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-169-4df045607c57>\", line 16, in <module>\n    name='char_embedding')(character_input)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 213, in call\n    y = self.layer.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1215, in gather\n    return tf.gather(reference, indices)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1179, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2106150,52,100]\n\t [[Node: char_embedding_6/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](char_embedding_6/embeddings/read, char_embedding_6/Cast)]]\n\t [[Node: chain_crf_7/strided_slice_10/_1869 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5435_chain_crf_7/strided_slice_10\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2106150,52,100]\n\t [[Node: char_embedding_6/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](char_embedding_6/embeddings/read, char_embedding_6/Cast)]]\n\t [[Node: chain_crf_7/strided_slice_10/_1869 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5435_chain_crf_7/strided_slice_10\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-df212c6409aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2106150,52,100]\n\t [[Node: char_embedding_6/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](char_embedding_6/embeddings/read, char_embedding_6/Cast)]]\n\t [[Node: chain_crf_7/strided_slice_10/_1869 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5435_chain_crf_7/strided_slice_10\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'char_embedding_6/Gather', defined at:\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-169-4df045607c57>\", line 16, in <module>\n    name='char_embedding')(character_input)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 213, in call\n    y = self.layer.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1215, in gather\n    return tf.gather(reference, indices)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1179, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2106150,52,100]\n\t [[Node: char_embedding_6/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](char_embedding_6/embeddings/read, char_embedding_6/Cast)]]\n\t [[Node: chain_crf_7/strided_slice_10/_1869 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_5435_chain_crf_7/strided_slice_10\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model.train_on_batch([train_word, train_char],train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100\n",
      " \n",
      "Epoch 1/100\n",
      " \n",
      "Epoch 2/100\n",
      " \n",
      "Epoch 3/100\n",
      " \n",
      "Epoch 4/100\n",
      " \n",
      "Epoch 5/100\n",
      " \n",
      "Epoch 6/100\n",
      " \n",
      "Epoch 7/100\n",
      " \n",
      "Epoch 8/100\n",
      " \n",
      "Epoch 9/100\n",
      " \n",
      "Epoch 10/100\n",
      " \n",
      "Epoch 11/100\n",
      " \n",
      "Epoch 12/100\n",
      " \n",
      "Epoch 13/100\n",
      " \n",
      "Epoch 14/100\n",
      " \n",
      "Epoch 15/100\n",
      " \n",
      "Epoch 16/100\n",
      " \n",
      "Epoch 17/100\n",
      " \n",
      "Epoch 18/100\n",
      " \n",
      "Epoch 19/100\n",
      " \n",
      "Epoch 20/100\n",
      " \n",
      "Epoch 21/100\n",
      " \n",
      "Epoch 22/100\n",
      " \n",
      "Epoch 23/100\n",
      " \n",
      "Epoch 24/100\n",
      " \n",
      "Epoch 25/100\n",
      " \n",
      "Epoch 26/100\n",
      " \n",
      "Epoch 27/100\n",
      " \n",
      "Epoch 28/100\n",
      " \n",
      "Epoch 29/100\n",
      " \n",
      "Epoch 30/100\n",
      " \n",
      "Epoch 31/100\n",
      " \n",
      "Epoch 32/100\n",
      " \n",
      "Epoch 33/100\n",
      " \n",
      "Epoch 34/100\n",
      " \n",
      "Epoch 35/100\n",
      " \n",
      "Epoch 36/100\n",
      " \n",
      "Epoch 37/100\n",
      " \n",
      "Epoch 38/100\n",
      " \n",
      "Epoch 39/100\n",
      " \n",
      "Epoch 40/100\n",
      " \n",
      "Epoch 41/100\n",
      " \n",
      "Epoch 42/100\n",
      " \n",
      "Epoch 43/100\n",
      " \n",
      "Epoch 44/100\n",
      " \n",
      "Epoch 45/100\n",
      " \n",
      "Epoch 46/100\n",
      " \n",
      "Epoch 47/100\n",
      " \n",
      "Epoch 48/100\n",
      " \n",
      "Epoch 49/100\n",
      " \n",
      "Epoch 50/100\n",
      " \n",
      "Epoch 51/100\n",
      " \n",
      "Epoch 52/100\n",
      " \n",
      "Epoch 53/100\n",
      " \n",
      "Epoch 54/100\n",
      " \n",
      "Epoch 55/100\n",
      " \n",
      "Epoch 56/100\n",
      " \n",
      "Epoch 57/100\n",
      " \n",
      "Epoch 58/100\n",
      " \n",
      "Epoch 59/100\n",
      " \n",
      "Epoch 60/100\n",
      " \n",
      "Epoch 61/100\n",
      " \n",
      "Epoch 62/100\n",
      " \n",
      "Epoch 63/100\n",
      " \n",
      "Epoch 64/100\n",
      " \n",
      "Epoch 65/100\n",
      " \n",
      "Epoch 66/100\n",
      " \n",
      "Epoch 67/100\n",
      " \n",
      "Epoch 68/100\n",
      " \n",
      "Epoch 69/100\n",
      " \n",
      "Epoch 70/100\n",
      " \n",
      "Epoch 71/100\n",
      " \n",
      "Epoch 72/100\n",
      " \n",
      "Epoch 73/100\n",
      " \n",
      "Epoch 74/100\n",
      " \n",
      "Epoch 75/100\n",
      " \n",
      "Epoch 76/100\n",
      " \n",
      "Epoch 77/100\n",
      " \n",
      "Epoch 78/100\n",
      " \n",
      "Epoch 79/100\n",
      " \n",
      "Epoch 80/100\n",
      " \n",
      "Epoch 81/100\n",
      " \n",
      "Epoch 82/100\n",
      " \n",
      "Epoch 83/100\n",
      " \n",
      "Epoch 84/100\n",
      " \n",
      "Epoch 85/100\n",
      " \n",
      "Epoch 86/100\n",
      " \n",
      "Epoch 87/100\n",
      " \n",
      "Epoch 88/100\n",
      " \n",
      "Epoch 89/100\n",
      " \n",
      "Epoch 90/100\n",
      " \n",
      "Epoch 91/100\n",
      " \n",
      "Epoch 92/100\n",
      " \n",
      "Epoch 93/100\n",
      " \n",
      "Epoch 94/100\n",
      " \n",
      "Epoch 95/100\n",
      " \n",
      "Epoch 96/100\n",
      " \n",
      "Epoch 97/100\n",
      " \n",
      "Epoch 98/100\n",
      " \n",
      "Epoch 99/100\n",
      " \n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "for epoch in range(epochs):    \n",
    "    print(\"Epoch %d/%d\"%(epoch,epochs))\n",
    "    a = Progbar(len(list(train_batches)))\n",
    "    for idx, batch in enumerate(train_batches):\n",
    "        batch_word, batch_char, batch_labels = batch\n",
    "        model.train_on_batch([batch_word, batch_char], batch_labels)\n",
    "        a.update(idx)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tag_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-3d9119db5d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrectLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpre_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrectLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2Label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tag_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "predLabels, correctLabels = tag_dataset(dev_batch)\n",
    "pre_dev, rec_dev, f1_dev = compute_f1(predLabels, correctLabels, idx2Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 5, 6, 6, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'LOC ', u'PER ', u'MISC ', u'ORG ', u'O ']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 59, 6)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 59, 52)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.argmax(train_labels, axis=2).reshape((len(train_labels), 150, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 200\n",
      "200 400\n",
      "400 600\n",
      "600 800\n",
      "800 1000\n",
      "1000 1200\n",
      "1200 1400\n",
      "1400 1600\n",
      "1600 1800\n",
      "1800 2000\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    i_start, i_end = i*200, (i+1)*200\n",
    "    print(i_start, i_end)\n",
    "    model.train_on_batch([train_word[i_start:i_end, 0:20], train_char[i_start:i_end, 0:20,:]], train_labels[i_start:i_end, 0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Far East gold traders thumped foreheads in frustration at the market 's foot-dragging this week and forecast on Friday that next week would not be much better . \n",
      "2000 Crystal Palace 4 1 2 1 4 3 5 \n",
      "3000 South Korea in 1993 unconditionally repatriated Li In-mo , a nothern partisan seized by the South during the war and jailed for more than three decades . \n"
     ]
    }
   ],
   "source": [
    "docs = get_ner_sentences('eng.testa')\n",
    "wx.index = list(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-5eb6044eeb54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m   5160\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m   5161\u001b[0m                        \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5162\u001b[0;31m                        **kwargs)\n\u001b[0m\u001b[1;32m   5163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5164\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1757\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                                                     mutated=self.mutated)\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, mutated, validate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m                         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m                         in_axis=in_axis) \\\n\u001b[0;32m-> 2863\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouping\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2865\u001b[0m         \u001b[0mgroupings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, index, grouper, obj, name, level, sort, in_axis)\u001b[0m\n\u001b[1;32m   2612\u001b[0m                     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2613\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Grouper for '%s' not 1-dimensional\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2614\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2615\u001b[0m                 if not (hasattr(self.grouper, \"__len__\") and\n\u001b[1;32m   2616\u001b[0m                         len(self.grouper) == len(self.index)):\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, mapper)\u001b[0m\n\u001b[1;32m   2879\u001b[0m         \"\"\"\n\u001b[1;32m   2880\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2881\u001b[0;31m         \u001b[0mmapped_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arrmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2882\u001b[0m         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_attributes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2883\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmapped_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/algos_common_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.algos.arrmap_object\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-171-5eb6044eeb54>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "wx.groupby(lambda x: len(x.iloc[0]>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      168920\n",
       "1        9860\n",
       "2       10270\n",
       "3        3876\n",
       "4       17661\n",
       "5       10186\n",
       "6      217839\n",
       "7       52637\n",
       "8           0\n",
       "9           0\n",
       "10          0\n",
       "11          0\n",
       "12          0\n",
       "13          0\n",
       "14          0\n",
       "15          0\n",
       "16          0\n",
       "17          0\n",
       "18          0\n",
       "19          0\n",
       "20          0\n",
       "21          0\n",
       "22          0\n",
       "23          0\n",
       "24          0\n",
       "25          0\n",
       "26          0\n",
       "27          0\n",
       "28          0\n",
       "29          0\n",
       "        ...  \n",
       "120         0\n",
       "121         0\n",
       "122         0\n",
       "123         0\n",
       "124         0\n",
       "125         0\n",
       "126         0\n",
       "127         0\n",
       "128         0\n",
       "129         0\n",
       "130         0\n",
       "131         0\n",
       "132         0\n",
       "133         0\n",
       "134         0\n",
       "135         0\n",
       "136         0\n",
       "137         0\n",
       "138         0\n",
       "139         0\n",
       "140         0\n",
       "141         0\n",
       "142         0\n",
       "143         0\n",
       "144         0\n",
       "145         0\n",
       "146         0\n",
       "147         0\n",
       "148         0\n",
       "149         0\n",
       "Name: (CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, TOP, AFTER, INNINGS, VICTORY, .), Length: 150, dtype: int32"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wx.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_lens = (word_X>0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 150, 52)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_char[i*100:(i+1)*100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 13,\n",
       "         1: 55,\n",
       "         2: 138,\n",
       "         3: 153,\n",
       "         4: 399,\n",
       "         5: 279,\n",
       "         6: 182,\n",
       "         7: 153,\n",
       "         8: 217,\n",
       "         9: 114,\n",
       "         10: 86,\n",
       "         11: 60,\n",
       "         12: 53,\n",
       "         13: 57,\n",
       "         14: 49,\n",
       "         15: 60,\n",
       "         16: 53,\n",
       "         17: 68,\n",
       "         18: 63,\n",
       "         19: 58,\n",
       "         20: 70,\n",
       "         21: 54,\n",
       "         22: 52,\n",
       "         23: 44,\n",
       "         24: 63,\n",
       "         25: 55,\n",
       "         26: 60,\n",
       "         27: 45,\n",
       "         28: 48,\n",
       "         29: 51,\n",
       "         30: 47,\n",
       "         31: 42,\n",
       "         32: 38,\n",
       "         33: 44,\n",
       "         34: 40,\n",
       "         35: 33,\n",
       "         36: 26,\n",
       "         37: 19,\n",
       "         38: 15,\n",
       "         39: 17,\n",
       "         40: 21,\n",
       "         41: 9,\n",
       "         42: 10,\n",
       "         43: 5,\n",
       "         44: 7,\n",
       "         45: 1,\n",
       "         46: 4,\n",
       "         47: 3,\n",
       "         48: 2,\n",
       "         49: 2,\n",
       "         50: 6,\n",
       "         51: 3,\n",
       "         53: 1,\n",
       "         54: 1,\n",
       "         56: 1,\n",
       "         59: 1})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(sent_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False (1, 150)\n",
      "True (3249, 150)\n"
     ]
    }
   ],
   "source": [
    "for i,g in wx.groupby(lambda x: x>0):\n",
    "    print(i,g.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "    batch = []\n",
    "    for idx, doc in enumerate(docs):\n",
    "        batch.append(doc)\n",
    "        if idx%batch_size==(batch_size-1):\n",
    "            word_X = get_word_emb_features(batch, 150)\n",
    "            char_X = get_char_emb_features(batch)\n",
    "            batch=[]\n",
    "#             print(idx)\n",
    "            #print((idx-batch_size+1 ,(idx+1)))\n",
    "            yield word_X, char_X, doc_labels[(idx-batch_size+1) : (idx+1),], LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-76b30aefe4d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABELS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eng.train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-61b546c24fdd>\u001b[0m in \u001b[0;36mget_batch_data\u001b[0;34m(file_str)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-41d46bf0f570>\u001b[0m in \u001b[0;36mget_ner_sentences\u001b[0;34m(filex)\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msent_count\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0msent\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/spacy/language.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.parse_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.get_batch_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.precompute_hiddens.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/spacy/_ml.pyc\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         Yf = self.ops.xp.dot(X,\n\u001b[0;32m--> 148\u001b[0;31m             self.W.reshape((self.nF*self.nO*self.nP, self.nI)).T)\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mYf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mYf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for words, chars, labels, LABELS in get_batch_data('eng.train'):\n",
    "    print(words.shape, chars.shape, labels.shape)\n",
    "    #break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 150)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'\\n': 0,\n",
       " u' ': 1,\n",
       " u'!': 2,\n",
       " u'\"': 3,\n",
       " u'#': 4,\n",
       " u'$': 5,\n",
       " u'%': 6,\n",
       " u'&': 7,\n",
       " u\"'\": 8,\n",
       " u'(': 9,\n",
       " u')': 10,\n",
       " u'*': 11,\n",
       " u'+': 12,\n",
       " u',': 13,\n",
       " u'-': 14,\n",
       " u'.': 15,\n",
       " u'/': 16,\n",
       " u'0': 17,\n",
       " u'1': 18,\n",
       " u'2': 19,\n",
       " u'3': 20,\n",
       " u'4': 21,\n",
       " u'5': 22,\n",
       " u'6': 23,\n",
       " u'7': 24,\n",
       " u'8': 25,\n",
       " u'9': 26,\n",
       " u':': 27,\n",
       " u';': 28,\n",
       " u'=': 29,\n",
       " u'?': 30,\n",
       " u'@': 31,\n",
       " u'A': 32,\n",
       " u'B': 33,\n",
       " u'C': 34,\n",
       " u'D': 35,\n",
       " u'E': 36,\n",
       " u'F': 37,\n",
       " u'G': 38,\n",
       " u'H': 39,\n",
       " u'I': 40,\n",
       " u'J': 41,\n",
       " u'K': 42,\n",
       " u'L': 43,\n",
       " u'M': 44,\n",
       " u'N': 45,\n",
       " u'O': 46,\n",
       " u'P': 47,\n",
       " u'Q': 48,\n",
       " u'R': 49,\n",
       " u'S': 50,\n",
       " u'T': 51,\n",
       " u'U': 52,\n",
       " u'V': 53,\n",
       " u'W': 54,\n",
       " u'X': 55,\n",
       " u'Y': 56,\n",
       " u'Z': 57,\n",
       " u'[': 58,\n",
       " u']': 59,\n",
       " u'`': 60,\n",
       " u'a': 61,\n",
       " u'b': 62,\n",
       " u'c': 63,\n",
       " u'd': 64,\n",
       " u'e': 65,\n",
       " u'f': 66,\n",
       " u'g': 67,\n",
       " u'h': 68,\n",
       " u'i': 69,\n",
       " u'j': 70,\n",
       " u'k': 71,\n",
       " u'l': 72,\n",
       " u'm': 73,\n",
       " u'n': 74,\n",
       " u'o': 75,\n",
       " u'p': 76,\n",
       " u'q': 77,\n",
       " u'r': 78,\n",
       " u's': 79,\n",
       " u't': 80,\n",
       " u'u': 81,\n",
       " u'v': 82,\n",
       " u'w': 83,\n",
       " u'x': 84,\n",
       " u'y': 85,\n",
       " u'z': 86,\n",
       " u'|': 87}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ..., \n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True, False, ..., False, False, False]], dtype=bool)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50\n",
      "batch: 0\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 1\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 2\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 3\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 4\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 5\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 6\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 7\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 8\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "1000 The youth side replied with 246 for seven . \n",
      "batch: 9\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 10\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 11\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 12\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 13\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n",
      "batch: 14\n",
      "(100, 150) (100, 150, 52) (100, 150, 6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-965f3e3e3880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d/%d\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eng.train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#dirty fix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-61b546c24fdd>\u001b[0m in \u001b[0;36mget_batch_data\u001b[0;34m(file_str)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-41d46bf0f570>\u001b[0m in \u001b[0;36mget_ner_sentences\u001b[0;34m(filex)\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0msent_count\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0msent\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/spacy/language.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.parse_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.get_batch_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/thinc/api.pyc\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/thinc/api.pyc\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         X, bp_layer = layer.begin_update(layer.ops.flatten(seqs_in, pad=pad),\n\u001b[0;32m--> 280\u001b[0;31m                                          drop=drop)\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/thinc/api.pyc\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/thinc/neural/_classes/resnet.pyc\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mresidual_bwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/thinc/api.pyc\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/thinc/neural/_classes/layernorm.pyc\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/thinc/neural/_classes/maxout.pyc\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X__bi, drop)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdrop\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__bi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(epochs):    \n",
    "    print(\"Epoch %d/%d\"%(epoch,epochs))\n",
    "    \n",
    "    for i_batch, batch in enumerate(get_batch_data('eng.train')):\n",
    "        words, chars, labels, LABELS = batch\n",
    "        #dirty fix\n",
    "        print('batch:', i_batch)\n",
    "        print(words.shape, chars.shape, labels.shape)\n",
    "        #batch_size=100\n",
    "        labels = np.argmax(labels, axis=2).reshape((100, 150, 1))\n",
    "        model.train_on_batch([words,  chars], labels)\n",
    "    \n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 150)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reshape() takes exactly 1 argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-5b790288ba19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: reshape() takes exactly 1 argument (0 given)"
     ]
    }
   ],
   "source": [
    "labels.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4],\n",
       "        [5],\n",
       "        [3],\n",
       "        ..., \n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[2],\n",
       "        [2],\n",
       "        [0],\n",
       "        ..., \n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[1],\n",
       "        [5],\n",
       "        [0],\n",
       "        ..., \n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       ..., \n",
       "       [[1],\n",
       "        [5],\n",
       "        [5],\n",
       "        ..., \n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[2],\n",
       "        [2],\n",
       "        [5],\n",
       "        ..., \n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[5],\n",
       "        [5],\n",
       "        [5],\n",
       "        ..., \n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(labels, axis=2).reshape((1000, 150, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 The youth side replied with 246 for seven . \n",
      "2000 Unseeded Patrick Rafter recorded the most noteworthy result as he upset sixth-seeded American MaliVai Washington 6-2 6-1 in just 50 minutes . \n",
      "3000 Their release has been negotiated by Islamist writer Ismail Nacar as part of a wider effort , partly backed by Prime Minister Necmettin Erbakan , to find a political solution to Turkey 's Kurdish problem . \n",
      "4000 Lille 3 Rennes 1 \n",
      "5000 Waqar Younis not out 0 \n",
      "6000 Thai army commanders reject the explanation , saying they have evidence the Burmese army supplies and directs the renegade ethnic minority splinter faction . \n",
      "7000 But Stich did n't want to play that game . \n",
      "8000 - Fears of an Israeli operation causes the redistribution of Syrian troops locations in Lebanon . \n",
      "9000 But Meri , 67 , has been accused in parliament of taking too much power and not always consulting parliamentarians before making decisions . \n",
      "10000 Men 's 3,000 metres : \n",
      "11000 Austrian composer and organist , he wrote nine symphonies on a huge scale and three grand masses in the romantic tradition . \n",
      "12000 MOF 's Kubo says believes BOJ rate policy unchanged . \n",
      "13000 The tabloid Star magazine reported the married Morris had a lengthy affair with a $ 200-an-hour prostitute who he allowed to eavesdrop on telephone conversations with Clinton , and with whom he shared White House speeches before they were made . \n",
      "14000 for Sunday 's San Marino 500cc motorcycling Grand Prix : \n",
      "1000 Woman charged over N. Ireland arms find . \n",
      "2000 One of the dead was a civilian passer-by . \n",
      "3000 Chesterfield 21 11 4 6 22 16 37 \n",
      "12\n",
      "2\n",
      "12\n",
      "27\n",
      "27\n",
      "42\n",
      "23\n",
      "17\n",
      "18\n",
      "28\n",
      "38\n",
      "12\n",
      "31\n",
      "18\n",
      "21\n",
      "9\n",
      "17\n",
      "20\n",
      "1\n",
      "28\n",
      "17\n",
      "13\n",
      "11\n",
      "6\n",
      "4\n",
      "28\n",
      "38\n",
      "34\n",
      "29\n",
      "14\n",
      "15\n",
      "19\n",
      "13\n",
      "66\n",
      "10\n",
      "12\n",
      "23\n",
      "34\n",
      "11\n",
      "31\n",
      "15\n",
      "22\n",
      "21\n",
      "27\n",
      "19\n",
      "30\n",
      "71\n",
      "74\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "1\n",
      "9\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "12\n",
      "11\n",
      "10\n",
      "2\n",
      "12\n",
      "5\n",
      "4\n",
      "10\n",
      "9\n",
      "3\n",
      "13\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "5\n",
      "8\n",
      "4\n",
      "10\n",
      "3\n",
      "1\n",
      "10\n",
      "10\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "10\n",
      "38\n",
      "27\n",
      "33\n",
      "12\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "5\n",
      "9\n",
      "6\n",
      "6\n",
      "8\n",
      "11\n",
      "5\n",
      "8\n",
      "9\n",
      "25\n",
      "7\n",
      "19\n",
      "25\n",
      "31\n",
      "10\n",
      "8\n",
      "12\n",
      "9\n",
      "6\n",
      "6\n",
      "7\n",
      "4\n",
      "6\n",
      "6\n",
      "27\n",
      "33\n",
      "28\n",
      "23\n",
      "24\n",
      "14\n",
      "6\n",
      "35\n",
      "27\n",
      "29\n",
      "29\n",
      "29\n",
      "5\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "2\n",
      "8\n",
      "9\n",
      "10\n",
      "9\n",
      "8\n",
      "8\n",
      "2\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "2\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "2\n",
      "6\n",
      "21\n",
      "30\n",
      "30\n",
      "47\n",
      "38\n",
      "43\n",
      "39\n",
      "32\n",
      "37\n",
      "2\n",
      "124\n",
      "80\n",
      "8\n",
      "6\n",
      "56\n",
      "42\n",
      "12\n",
      "24\n",
      "23\n",
      "9\n",
      "9\n",
      "6\n",
      "25\n",
      "32\n",
      "27\n",
      "16\n",
      "29\n",
      "25\n",
      "2\n",
      "8\n",
      "23\n",
      "23\n",
      "14\n",
      "1\n",
      "6\n",
      "8\n",
      "3\n",
      "10\n",
      "4\n",
      "5\n",
      "8\n",
      "2\n",
      "6\n",
      "28\n",
      "22\n",
      "43\n",
      "27\n",
      "30\n",
      "24\n",
      "25\n",
      "15\n",
      "23\n",
      "25\n",
      "27\n",
      "29\n",
      "21\n",
      "10\n",
      "6\n",
      "5\n",
      "11\n",
      "2\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "28\n",
      "4\n",
      "23\n",
      "30\n",
      "10\n",
      "1\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "10\n",
      "20\n",
      "16\n",
      "27\n",
      "26\n",
      "11\n",
      "8\n",
      "10\n",
      "6\n",
      "22\n",
      "31\n",
      "13\n",
      "6\n",
      "22\n",
      "6\n",
      "8\n",
      "23\n",
      "24\n",
      "9\n",
      "6\n",
      "36\n",
      "35\n",
      "34\n",
      "30\n",
      "17\n",
      "18\n",
      "20\n",
      "34\n",
      "11\n",
      "39\n",
      "35\n",
      "17\n",
      "26\n",
      "18\n",
      "11\n",
      "6\n",
      "33\n",
      "2\n",
      "43\n",
      "44\n",
      "7\n",
      "6\n",
      "17\n",
      "3\n",
      "2\n",
      "18\n",
      "19\n",
      "21\n",
      "2\n",
      "17\n",
      "18\n",
      "2\n",
      "22\n",
      "17\n",
      "13\n",
      "14\n",
      "3\n",
      "3\n",
      "2\n",
      "17\n",
      "2\n",
      "16\n",
      "2\n",
      "17\n",
      "2\n",
      "18\n",
      "30\n",
      "11\n",
      "6\n",
      "37\n",
      "2\n",
      "12\n",
      "8\n",
      "10\n",
      "7\n",
      "4\n",
      "10\n",
      "15\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "8\n",
      "5\n",
      "7\n",
      "21\n",
      "1\n",
      "4\n",
      "11\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "13\n",
      "6\n",
      "35\n",
      "46\n",
      "33\n",
      "10\n",
      "13\n",
      "31\n",
      "23\n",
      "22\n",
      "26\n",
      "15\n",
      "15\n",
      "39\n",
      "33\n",
      "14\n",
      "27\n",
      "9\n",
      "7\n",
      "3\n",
      "8\n",
      "13\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "7\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "10\n",
      "7\n",
      "3\n",
      "12\n",
      "9\n",
      "3\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "5\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "2\n",
      "5\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "8\n",
      "7\n",
      "4\n",
      "11\n",
      "4\n",
      "14\n",
      "6\n",
      "35\n",
      "25\n",
      "21\n",
      "18\n",
      "27\n",
      "38\n",
      "9\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "13\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "13\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "14\n",
      "8\n",
      "5\n",
      "2\n",
      "2\n",
      "14\n",
      "7\n",
      "4\n",
      "2\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "15\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "12\n",
      "12\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "7\n",
      "6\n",
      "12\n",
      "21\n",
      "5\n",
      "3\n",
      "15\n",
      "5\n",
      "2\n",
      "15\n",
      "5\n",
      "2\n",
      "12\n",
      "5\n",
      "2\n",
      "10\n",
      "8\n",
      "34\n",
      "20\n",
      "11\n",
      "6\n",
      "46\n",
      "26\n",
      "29\n",
      "8\n",
      "2\n",
      "16\n",
      "59\n",
      "36\n",
      "38\n",
      "10\n",
      "6\n",
      "6\n",
      "10\n",
      "13\n",
      "5\n",
      "3\n",
      "7\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "1\n",
      "10\n",
      "9\n",
      "1\n",
      "8\n",
      "1\n",
      "10\n",
      "1\n",
      "9\n",
      "1\n",
      "8\n",
      "1\n",
      "10\n",
      "9\n",
      "1\n",
      "10\n",
      "3\n",
      "2\n",
      "11\n",
      "6\n",
      "36\n",
      "21\n",
      "21\n",
      "7\n",
      "6\n",
      "5\n",
      "8\n",
      "15\n",
      "5\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "6\n",
      "26\n",
      "7\n",
      "20\n",
      "9\n",
      "6\n",
      "33\n",
      "31\n",
      "26\n",
      "19\n",
      "38\n",
      "20\n",
      "20\n",
      "14\n",
      "11\n",
      "23\n",
      "20\n",
      "11\n",
      "9\n",
      "6\n",
      "24\n",
      "22\n",
      "11\n",
      "9\n",
      "29\n",
      "7\n",
      "9\n",
      "6\n",
      "22\n",
      "10\n",
      "18\n",
      "40\n",
      "10\n",
      "27\n",
      "14\n",
      "10\n",
      "46\n",
      "11\n",
      "26\n",
      "39\n",
      "11\n",
      "6\n",
      "21\n",
      "21\n",
      "17\n",
      "10\n",
      "24\n",
      "19\n",
      "10\n",
      "39\n",
      "21\n",
      "11\n",
      "10\n",
      "26\n",
      "26\n",
      "10\n",
      "13\n",
      "34\n",
      "16\n",
      "5\n",
      "6\n",
      "9\n",
      "2\n",
      "3\n",
      "16\n",
      "3\n",
      "13\n",
      "13\n",
      "2\n",
      "3\n",
      "18\n",
      "3\n",
      "5\n",
      "5\n",
      "11\n",
      "8\n",
      "43\n",
      "18\n",
      "27\n",
      "20\n",
      "11\n",
      "7\n",
      "8\n",
      "12\n",
      "41\n",
      "9\n",
      "9\n",
      "9\n",
      "26\n",
      "47\n",
      "21\n",
      "23\n",
      "18\n",
      "6\n",
      "42\n",
      "39\n",
      "32\n",
      "8\n",
      "2\n",
      "6\n",
      "30\n",
      "35\n",
      "10\n",
      "19\n",
      "14\n",
      "42\n",
      "18\n",
      "32\n",
      "23\n",
      "39\n",
      "4\n",
      "43\n",
      "19\n",
      "44\n",
      "8\n",
      "6\n",
      "5\n",
      "29\n",
      "9\n",
      "26\n",
      "21\n",
      "22\n",
      "7\n",
      "11\n",
      "6\n",
      "38\n",
      "20\n",
      "20\n",
      "50\n",
      "17\n",
      "36\n",
      "38\n",
      "30\n",
      "22\n",
      "37\n",
      "10\n",
      "10\n",
      "2\n",
      "6\n",
      "38\n",
      "30\n",
      "17\n",
      "22\n",
      "50\n",
      "24\n",
      "40\n",
      "27\n",
      "26\n",
      "27\n",
      "23\n",
      "20\n",
      "31\n",
      "45\n",
      "17\n",
      "10\n",
      "2\n",
      "6\n",
      "41\n",
      "55\n",
      "28\n",
      "7\n",
      "38\n",
      "42\n",
      "35\n",
      "43\n",
      "15\n",
      "55\n",
      "29\n",
      "14\n",
      "38\n",
      "41\n",
      "31\n",
      "22\n",
      "44\n",
      "35\n",
      "35\n",
      "41\n",
      "8\n",
      "7\n",
      "6\n",
      "28\n",
      "33\n",
      "23\n",
      "23\n",
      "12\n",
      "21\n",
      "26\n",
      "27\n",
      "13\n",
      "6\n",
      "42\n",
      "24\n",
      "14\n",
      "10\n",
      "8\n",
      "6\n",
      "14\n",
      "18\n",
      "8\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "15\n",
      "18\n",
      "9\n",
      "15\n",
      "8\n",
      "6\n",
      "26\n",
      "20\n",
      "30\n",
      "8\n",
      "6\n",
      "32\n",
      "8\n",
      "2\n",
      "6\n",
      "39\n",
      "50\n",
      "24\n",
      "55\n",
      "21\n",
      "29\n",
      "26\n",
      "21\n",
      "22\n",
      "29\n",
      "21\n",
      "59\n",
      "15\n",
      "35\n",
      "18\n",
      "10\n",
      "6\n",
      "23\n",
      "18\n",
      "26\n",
      "15\n",
      "30\n",
      "20\n",
      "17\n",
      "24\n",
      "36\n",
      "29\n",
      "17\n",
      "18\n",
      "30\n",
      "6\n",
      "6\n",
      "36\n",
      "25\n",
      "20\n",
      "14\n",
      "20\n",
      "16\n",
      "16\n",
      "19\n",
      "19\n",
      "23\n",
      "7\n",
      "36\n",
      "9\n",
      "6\n",
      "42\n",
      "20\n",
      "19\n",
      "18\n",
      "38\n",
      "23\n",
      "49\n",
      "10\n",
      "7\n",
      "6\n",
      "29\n",
      "18\n",
      "37\n",
      "18\n",
      "17\n",
      "10\n",
      "13\n",
      "6\n",
      "25\n",
      "20\n",
      "11\n",
      "9\n",
      "10\n",
      "8\n",
      "27\n",
      "10\n",
      "10\n",
      "6\n",
      "23\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "12\n",
      "3\n",
      "11\n",
      "8\n",
      "5\n",
      "11\n",
      "8\n",
      "6\n",
      "24\n",
      "13\n",
      "14\n",
      "17\n",
      "3\n",
      "3\n",
      "4\n",
      "10\n",
      "8\n",
      "7\n",
      "8\n",
      "10\n",
      "12\n",
      "7\n",
      "21\n",
      "10\n",
      "9\n",
      "7\n",
      "2\n",
      "3\n",
      "9\n",
      "11\n",
      "9\n",
      "7\n",
      "5\n",
      "12\n",
      "2\n",
      "11\n",
      "10\n",
      "9\n",
      "10\n",
      "10\n",
      "7\n",
      "31\n",
      "47\n",
      "32\n",
      "45\n",
      "35\n",
      "16\n",
      "17\n",
      "9\n",
      "8\n",
      "7\n",
      "30\n",
      "2\n",
      "8\n",
      "2\n",
      "7\n",
      "31\n",
      "23\n",
      "40\n",
      "16\n",
      "30\n",
      "22\n",
      "33\n",
      "35\n",
      "35\n",
      "34\n",
      "17\n",
      "21\n",
      "21\n",
      "29\n",
      "28\n",
      "40\n",
      "26\n",
      "30\n",
      "28\n",
      "19\n",
      "23\n",
      "26\n",
      "45\n",
      "35\n",
      "11\n",
      "8\n",
      "8\n",
      "26\n",
      "30\n",
      "5\n",
      "6\n",
      "22\n",
      "11\n",
      "21\n",
      "8\n",
      "2\n",
      "6\n",
      "37\n",
      "45\n",
      "48\n",
      "39\n",
      "31\n",
      "28\n",
      "21\n",
      "28\n",
      "46\n",
      "21\n",
      "30\n",
      "51\n",
      "17\n",
      "26\n",
      "15\n",
      "18\n",
      "15\n",
      "20\n",
      "33\n",
      "18\n",
      "11\n",
      "17\n",
      "20\n",
      "50\n",
      "39\n",
      "23\n",
      "6\n",
      "7\n",
      "13\n",
      "45\n",
      "21\n",
      "26\n",
      "17\n",
      "15\n",
      "8\n",
      "6\n",
      "35\n",
      "28\n",
      "8\n",
      "6\n",
      "26\n",
      "33\n",
      "21\n",
      "21\n",
      "17\n",
      "23\n",
      "11\n",
      "2\n",
      "6\n",
      "34\n",
      "35\n",
      "33\n",
      "23\n",
      "38\n",
      "31\n",
      "15\n",
      "24\n",
      "32\n",
      "26\n",
      "22\n",
      "9\n",
      "21\n",
      "23\n",
      "9\n",
      "25\n",
      "37\n",
      "9\n",
      "12\n",
      "17\n",
      "14\n",
      "25\n",
      "19\n",
      "19\n",
      "18\n",
      "32\n",
      "21\n",
      "26\n",
      "9\n",
      "6\n",
      "33\n",
      "9\n",
      "17\n",
      "10\n",
      "6\n",
      "24\n",
      "7\n",
      "7\n",
      "6\n",
      "31\n",
      "26\n",
      "16\n",
      "8\n",
      "20\n",
      "16\n",
      "7\n",
      "8\n",
      "6\n",
      "34\n",
      "34\n",
      "16\n",
      "31\n",
      "23\n",
      "21\n",
      "9\n",
      "6\n",
      "37\n",
      "15\n",
      "17\n",
      "33\n",
      "1\n",
      "42\n",
      "37\n",
      "29\n",
      "10\n",
      "2\n",
      "6\n",
      "38\n",
      "34\n",
      "14\n",
      "34\n",
      "35\n",
      "29\n",
      "62\n",
      "32\n",
      "10\n",
      "43\n",
      "6\n",
      "42\n",
      "21\n",
      "20\n",
      "23\n",
      "31\n",
      "28\n",
      "26\n",
      "12\n",
      "27\n",
      "20\n",
      "30\n",
      "8\n",
      "9\n",
      "6\n",
      "28\n",
      "16\n",
      "17\n",
      "14\n",
      "24\n",
      "8\n",
      "8\n",
      "6\n",
      "25\n",
      "26\n",
      "15\n",
      "20\n",
      "14\n",
      "27\n",
      "38\n",
      "35\n",
      "11\n",
      "6\n",
      "38\n",
      "35\n",
      "22\n",
      "22\n",
      "32\n",
      "31\n",
      "27\n",
      "9\n",
      "6\n",
      "32\n",
      "39\n",
      "47\n",
      "14\n",
      "33\n",
      "21\n",
      "11\n",
      "8\n",
      "6\n",
      "26\n",
      "19\n",
      "21\n",
      "17\n",
      "7\n",
      "18\n",
      "13\n",
      "6\n",
      "25\n",
      "22\n",
      "11\n",
      "20\n",
      "19\n",
      "11\n",
      "18\n",
      "12\n",
      "10\n",
      "2\n",
      "20\n",
      "7\n",
      "49\n",
      "18\n",
      "9\n",
      "32\n",
      "20\n",
      "21\n",
      "17\n",
      "31\n",
      "16\n",
      "11\n",
      "21\n",
      "23\n",
      "20\n",
      "15\n",
      "14\n",
      "9\n",
      "16\n",
      "28\n",
      "7\n",
      "3\n",
      "8\n",
      "42\n",
      "46\n",
      "26\n",
      "31\n",
      "12\n",
      "19\n",
      "26\n",
      "25\n",
      "25\n",
      "19\n",
      "23\n",
      "31\n",
      "25\n",
      "39\n",
      "33\n",
      "31\n",
      "11\n",
      "31\n",
      "19\n",
      "8\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "8\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "10\n",
      "7\n",
      "24\n",
      "35\n",
      "19\n",
      "4\n",
      "22\n",
      "23\n",
      "37\n",
      "5\n",
      "22\n",
      "23\n",
      "3\n",
      "14\n",
      "17\n",
      "12\n",
      "10\n",
      "8\n",
      "29\n",
      "36\n",
      "16\n",
      "10\n",
      "6\n",
      "26\n",
      "29\n",
      "16\n",
      "44\n",
      "21\n",
      "20\n",
      "17\n",
      "31\n",
      "15\n",
      "9\n",
      "9\n",
      "31\n",
      "17\n",
      "12\n",
      "29\n",
      "37\n",
      "21\n",
      "20\n",
      "30\n",
      "18\n",
      "38\n",
      "10\n",
      "24\n",
      "35\n",
      "33\n",
      "31\n",
      "10\n",
      "6\n",
      "33\n",
      "17\n",
      "33\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "32\n",
      "38\n",
      "23\n",
      "33\n",
      "31\n",
      "16\n",
      "14\n",
      "8\n",
      "2\n",
      "6\n",
      "39\n",
      "22\n",
      "5\n",
      "24\n",
      "19\n",
      "18\n",
      "5\n",
      "37\n",
      "30\n",
      "9\n",
      "20\n",
      "29\n",
      "6\n",
      "31\n",
      "33\n",
      "10\n",
      "15\n",
      "27\n",
      "27\n",
      "22\n",
      "33\n",
      "17\n",
      "13\n",
      "20\n",
      "10\n",
      "6\n",
      "33\n",
      "53\n",
      "37\n",
      "42\n",
      "19\n",
      "17\n",
      "32\n",
      "35\n",
      "43\n",
      "17\n",
      "38\n",
      "32\n",
      "28\n",
      "7\n",
      "6\n",
      "38\n",
      "34\n",
      "23\n",
      "33\n",
      "22\n",
      "27\n",
      "17\n",
      "21\n",
      "44\n",
      "33\n",
      "8\n",
      "10\n",
      "2\n",
      "6\n",
      "38\n",
      "45\n",
      "41\n",
      "33\n",
      "36\n",
      "30\n",
      "10\n",
      "18\n",
      "19\n",
      "50\n",
      "43\n",
      "28\n",
      "21\n",
      "29\n",
      "53\n",
      "48\n",
      "22\n",
      "19\n",
      "30\n",
      "18\n",
      "48\n",
      "15\n",
      "9\n",
      "2\n",
      "6\n",
      "25\n",
      "29\n",
      "40\n",
      "30\n",
      "19\n",
      "53\n",
      "23\n",
      "28\n",
      "29\n",
      "24\n",
      "28\n",
      "35\n",
      "38\n",
      "35\n",
      "31\n",
      "14\n",
      "6\n",
      "12\n",
      "11\n",
      "5\n",
      "18\n",
      "18\n",
      "15\n",
      "15\n",
      "11\n",
      "9\n",
      "10\n",
      "9\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "7\n",
      "8\n",
      "9\n",
      "23\n",
      "9\n",
      "3\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "11\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "2\n",
      "7\n",
      "10\n",
      "10\n",
      "8\n",
      "21\n",
      "14\n",
      "37\n",
      "41\n",
      "32\n",
      "54\n",
      "27\n",
      "27\n",
      "14\n",
      "18\n",
      "19\n",
      "28\n",
      "17\n",
      "16\n",
      "7\n",
      "9\n",
      "7\n",
      "17\n",
      "10\n",
      "14\n",
      "7\n",
      "16\n",
      "3\n",
      "6\n",
      "3\n",
      "11\n",
      "11\n",
      "17\n",
      "11\n",
      "20\n",
      "28\n",
      "11\n",
      "11\n",
      "13\n",
      "11\n",
      "11\n",
      "4\n",
      "5\n",
      "32\n",
      "32\n",
      "7\n",
      "30\n",
      "28\n",
      "26\n",
      "15\n",
      "5\n",
      "19\n",
      "4\n",
      "4\n",
      "11\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "10\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "21\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "36\n",
      "22\n",
      "9\n",
      "6\n",
      "7\n",
      "26\n",
      "27\n",
      "25\n",
      "19\n",
      "12\n",
      "17\n",
      "26\n",
      "18\n",
      "19\n",
      "43\n",
      "15\n",
      "23\n",
      "25\n",
      "19\n",
      "17\n",
      "29\n",
      "14\n",
      "8\n",
      "8\n",
      "16\n",
      "8\n",
      "20\n",
      "24\n",
      "23\n",
      "28\n",
      "25\n",
      "32\n",
      "7\n",
      "8\n",
      "6\n",
      "27\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "11\n",
      "10\n",
      "6\n",
      "25\n",
      "40\n",
      "20\n",
      "21\n",
      "15\n",
      "6\n",
      "4\n",
      "5\n",
      "30\n",
      "28\n",
      "22\n",
      "10\n",
      "6\n",
      "33\n",
      "32\n",
      "39\n",
      "15\n",
      "11\n",
      "10\n",
      "20\n",
      "18\n",
      "43\n",
      "23\n",
      "25\n",
      "16\n",
      "13\n",
      "33\n",
      "11\n",
      "7\n",
      "16\n",
      "6\n",
      "6\n",
      "11\n",
      "7\n",
      "6\n",
      "9\n",
      "3\n",
      "4\n",
      "2\n",
      "10\n",
      "16\n",
      "7\n",
      "22\n",
      "18\n",
      "10\n",
      "2\n",
      "7\n",
      "35\n",
      "75\n",
      "39\n",
      "11\n",
      "31\n",
      "32\n",
      "17\n",
      "23\n",
      "39\n",
      "33\n",
      "10\n",
      "6\n",
      "31\n",
      "29\n",
      "18\n",
      "19\n",
      "9\n",
      "6\n",
      "37\n",
      "35\n",
      "18\n",
      "36\n",
      "19\n",
      "25\n",
      "48\n",
      "8\n",
      "8\n",
      "31\n",
      "34\n",
      "7\n",
      "6\n",
      "27\n",
      "18\n",
      "6\n",
      "9\n",
      "6\n",
      "23\n",
      "41\n",
      "18\n",
      "32\n",
      "31\n",
      "25\n",
      "14\n",
      "8\n",
      "7\n",
      "38\n",
      "42\n",
      "9\n",
      "22\n",
      "30\n",
      "27\n",
      "29\n",
      "18\n",
      "11\n",
      "7\n",
      "28\n",
      "10\n",
      "4\n",
      "6\n",
      "6\n",
      "11\n",
      "9\n",
      "6\n",
      "31\n",
      "21\n",
      "15\n",
      "6\n",
      "6\n",
      "33\n",
      "24\n",
      "24\n",
      "7\n",
      "6\n",
      "30\n",
      "15\n",
      "13\n",
      "8\n",
      "9\n",
      "10\n",
      "6\n",
      "23\n",
      "31\n",
      "13\n",
      "15\n",
      "8\n",
      "14\n",
      "26\n",
      "24\n",
      "23\n",
      "35\n",
      "18\n",
      "13\n",
      "27\n",
      "22\n",
      "17\n",
      "10\n",
      "10\n",
      "8\n",
      "6\n",
      "35\n",
      "37\n",
      "8\n",
      "9\n",
      "6\n",
      "35\n",
      "15\n",
      "25\n",
      "9\n",
      "29\n",
      "11\n",
      "9\n",
      "8\n",
      "31\n",
      "32\n",
      "47\n",
      "15\n",
      "20\n",
      "12\n",
      "28\n",
      "10\n",
      "11\n",
      "9\n",
      "6\n",
      "41\n",
      "16\n",
      "25\n",
      "10\n",
      "8\n",
      "24\n",
      "25\n",
      "21\n",
      "15\n",
      "10\n",
      "17\n",
      "19\n",
      "44\n",
      "24\n",
      "25\n",
      "23\n",
      "20\n",
      "9\n",
      "6\n",
      "38\n",
      "32\n",
      "20\n",
      "16\n",
      "25\n",
      "21\n",
      "19\n",
      "10\n",
      "17\n",
      "6\n",
      "15\n",
      "13\n",
      "10\n",
      "8\n",
      "30\n",
      "33\n",
      "11\n",
      "11\n",
      "38\n",
      "25\n",
      "28\n",
      "10\n",
      "6\n",
      "9\n",
      "8\n",
      "7\n",
      "2\n",
      "8\n",
      "10\n",
      "28\n",
      "15\n",
      "12\n",
      "7\n",
      "7\n",
      "3\n",
      "14\n",
      "2\n",
      "8\n",
      "10\n",
      "6\n",
      "12\n",
      "17\n",
      "13\n",
      "13\n",
      "7\n",
      "9\n",
      "4\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "10\n",
      "9\n",
      "7\n",
      "30\n",
      "15\n",
      "28\n",
      "27\n",
      "10\n",
      "28\n",
      "19\n",
      "13\n",
      "12\n",
      "7\n",
      "6\n",
      "37\n",
      "18\n",
      "29\n",
      "13\n",
      "26\n",
      "13\n",
      "23\n",
      "20\n",
      "39\n",
      "37\n",
      "11\n",
      "39\n",
      "26\n",
      "57\n",
      "8\n",
      "8\n",
      "33\n",
      "37\n",
      "14\n",
      "28\n",
      "42\n",
      "6\n",
      "2\n",
      "6\n",
      "33\n",
      "31\n",
      "34\n",
      "29\n",
      "28\n",
      "11\n",
      "44\n",
      "12\n",
      "5\n",
      "9\n",
      "35\n",
      "10\n",
      "11\n",
      "32\n",
      "26\n",
      "31\n",
      "17\n",
      "31\n",
      "15\n",
      "25\n",
      "8\n",
      "12\n",
      "19\n",
      "20\n",
      "48\n",
      "10\n",
      "8\n",
      "13\n",
      "16\n",
      "16\n",
      "33\n",
      "27\n",
      "26\n",
      "8\n",
      "9\n",
      "6\n",
      "31\n",
      "38\n",
      "27\n",
      "32\n",
      "8\n",
      "6\n",
      "37\n",
      "15\n",
      "28\n",
      "30\n",
      "30\n",
      "8\n",
      "8\n",
      "30\n",
      "47\n",
      "12\n",
      "14\n",
      "27\n",
      "15\n",
      "31\n",
      "24\n",
      "28\n",
      "32\n",
      "35\n",
      "8\n",
      "6\n",
      "23\n",
      "28\n",
      "31\n",
      "10\n",
      "8\n",
      "6\n",
      "20\n",
      "29\n",
      "10\n",
      "6\n",
      "33\n",
      "33\n",
      "26\n",
      "26\n",
      "8\n",
      "29\n",
      "23\n",
      "6\n",
      "7\n",
      "34\n",
      "8\n",
      "6\n",
      "34\n",
      "24\n",
      "36\n",
      "12\n",
      "9\n",
      "7\n",
      "8\n",
      "31\n",
      "22\n",
      "12\n",
      "37\n",
      "23\n",
      "8\n",
      "9\n",
      "6\n",
      "34\n",
      "38\n",
      "25\n",
      "7\n",
      "6\n",
      "6\n",
      "18\n",
      "6\n",
      "11\n",
      "6\n",
      "28\n",
      "19\n",
      "25\n",
      "10\n",
      "9\n",
      "6\n",
      "19\n",
      "14\n",
      "9\n",
      "9\n",
      "8\n",
      "11\n",
      "6\n",
      "37\n",
      "36\n",
      "9\n",
      "17\n",
      "5\n",
      "6\n",
      "16\n",
      "45\n",
      "28\n",
      "17\n",
      "22\n",
      "22\n",
      "10\n",
      "6\n",
      "33\n",
      "40\n",
      "34\n",
      "24\n",
      "34\n",
      "8\n",
      "33\n",
      "9\n",
      "21\n",
      "5\n",
      "23\n",
      "6\n",
      "6\n",
      "23\n",
      "46\n",
      "24\n",
      "23\n",
      "32\n",
      "38\n",
      "12\n",
      "12\n",
      "6\n",
      "33\n",
      "12\n",
      "12\n",
      "6\n",
      "25\n",
      "21\n",
      "18\n",
      "24\n",
      "9\n",
      "6\n",
      "26\n",
      "46\n",
      "15\n",
      "33\n",
      "29\n",
      "19\n",
      "28\n",
      "20\n",
      "9\n",
      "8\n",
      "6\n",
      "43\n",
      "20\n",
      "37\n",
      "28\n",
      "5\n",
      "30\n",
      "34\n",
      "10\n",
      "6\n",
      "17\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "8\n",
      "6\n",
      "45\n",
      "18\n",
      "24\n",
      "9\n",
      "6\n",
      "22\n",
      "14\n",
      "7\n",
      "36\n",
      "26\n",
      "10\n",
      "6\n",
      "28\n",
      "41\n",
      "35\n",
      "21\n",
      "9\n",
      "6\n",
      "38\n",
      "27\n",
      "43\n",
      "16\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "2\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "12\n",
      "11\n",
      "2\n",
      "6\n",
      "40\n",
      "26\n",
      "34\n",
      "38\n",
      "42\n",
      "30\n",
      "31\n",
      "33\n",
      "21\n",
      "7\n",
      "22\n",
      "33\n",
      "26\n",
      "35\n",
      "20\n",
      "33\n",
      "10\n",
      "15\n",
      "30\n",
      "47\n",
      "42\n",
      "6\n",
      "6\n",
      "30\n",
      "26\n",
      "20\n",
      "9\n",
      "2\n",
      "6\n",
      "40\n",
      "33\n",
      "33\n",
      "32\n",
      "43\n",
      "6\n",
      "10\n",
      "51\n",
      "47\n",
      "38\n",
      "33\n",
      "22\n",
      "39\n",
      "37\n",
      "21\n",
      "40\n",
      "23\n",
      "38\n",
      "25\n",
      "18\n",
      "19\n",
      "10\n",
      "6\n",
      "41\n",
      "20\n",
      "25\n",
      "38\n",
      "27\n",
      "20\n",
      "13\n",
      "23\n",
      "7\n",
      "8\n",
      "30\n",
      "21\n",
      "21\n",
      "37\n",
      "34\n",
      "16\n",
      "15\n",
      "12\n",
      "8\n",
      "15\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "29\n",
      "11\n",
      "8\n",
      "3\n",
      "10\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "9\n",
      "8\n",
      "6\n",
      "10\n",
      "8\n",
      "16\n",
      "20\n",
      "10\n",
      "9\n",
      "22\n",
      "19\n",
      "29\n",
      "31\n",
      "20\n",
      "18\n",
      "9\n",
      "8\n",
      "14\n",
      "4\n",
      "3\n",
      "3\n",
      "22\n",
      "33\n",
      "9\n",
      "8\n",
      "4\n",
      "7\n",
      "2\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "4\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "10\n",
      "8\n",
      "3\n",
      "9\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "4\n",
      "5\n",
      "4\n",
      "14\n",
      "2\n",
      "11\n",
      "12\n",
      "11\n",
      "11\n",
      "3\n",
      "8\n",
      "8\n",
      "5\n",
      "4\n",
      "11\n",
      "11\n",
      "12\n",
      "15\n",
      "11\n",
      "3\n",
      "4\n",
      "4\n",
      "8\n",
      "9\n",
      "8\n",
      "20\n",
      "14\n",
      "10\n",
      "8\n",
      "21\n",
      "34\n",
      "26\n",
      "33\n",
      "29\n",
      "25\n",
      "9\n",
      "8\n",
      "25\n",
      "38\n",
      "13\n",
      "21\n",
      "37\n",
      "34\n",
      "41\n",
      "25\n",
      "9\n",
      "8\n",
      "13\n",
      "13\n",
      "8\n",
      "12\n",
      "5\n",
      "12\n",
      "5\n",
      "12\n",
      "5\n",
      "12\n",
      "5\n",
      "12\n",
      "5\n",
      "12\n",
      "6\n",
      "12\n",
      "5\n",
      "14\n",
      "2\n",
      "3\n",
      "8\n",
      "11\n",
      "10\n",
      "3\n",
      "9\n",
      "8\n",
      "30\n",
      "25\n",
      "8\n",
      "23\n",
      "14\n",
      "21\n",
      "27\n",
      "14\n",
      "10\n",
      "15\n",
      "29\n",
      "17\n",
      "21\n",
      "24\n",
      "8\n",
      "8\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "2\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "10\n",
      "8\n",
      "4\n",
      "13\n",
      "12\n",
      "6\n",
      "13\n",
      "13\n",
      "13\n",
      "15\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "10\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "4\n",
      "4\n",
      "8\n",
      "8\n",
      "9\n",
      "2\n",
      "10\n",
      "3\n",
      "17\n",
      "18\n",
      "3\n",
      "14\n",
      "3\n",
      "17\n",
      "11\n",
      "9\n",
      "16\n",
      "9\n",
      "10\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "7\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "8\n",
      "9\n",
      "11\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "9\n",
      "31\n",
      "33\n",
      "21\n",
      "26\n",
      "33\n",
      "25\n",
      "8\n",
      "6\n",
      "4\n",
      "8\n",
      "14\n",
      "7\n",
      "13\n",
      "14\n",
      "8\n",
      "3\n",
      "11\n",
      "11\n",
      "13\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "7\n",
      "10\n",
      "3\n",
      "13\n",
      "15\n",
      "5\n",
      "13\n",
      "15\n",
      "4\n",
      "13\n",
      "8\n",
      "10\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "15\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "7\n",
      "6\n",
      "10\n",
      "22\n",
      "5\n",
      "3\n",
      "5\n",
      "1\n",
      "12\n",
      "4\n",
      "1\n",
      "16\n",
      "4\n",
      "1\n",
      "26\n",
      "4\n",
      "2\n",
      "9\n",
      "6\n",
      "26\n",
      "42\n",
      "26\n",
      "18\n",
      "21\n",
      "16\n",
      "30\n",
      "7\n",
      "6\n",
      "4\n",
      "5\n",
      "16\n",
      "3\n",
      "5\n",
      "3\n",
      "15\n",
      "4\n",
      "4\n",
      "1\n",
      "16\n",
      "4\n",
      "1\n",
      "13\n",
      "4\n",
      "1\n",
      "10\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "10\n",
      "4\n",
      "1\n",
      "15\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "6\n",
      "4\n",
      "15\n",
      "8\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "9\n",
      "6\n",
      "6\n",
      "5\n",
      "15\n",
      "9\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "2\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "6\n",
      "29\n",
      "47\n",
      "25\n",
      "28\n",
      "31\n",
      "8\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "6\n",
      "11\n",
      "12\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "12\n",
      "4\n",
      "4\n",
      "5\n",
      "14\n",
      "3\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "7\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "12\n",
      "6\n",
      "29\n",
      "40\n",
      "34\n",
      "21\n",
      "21\n",
      "10\n",
      "6\n",
      "24\n",
      "2\n",
      "19\n",
      "7\n",
      "7\n",
      "10\n",
      "5\n",
      "8\n",
      "6\n",
      "6\n",
      "11\n",
      "9\n",
      "6\n",
      "9\n",
      "12\n",
      "9\n",
      "7\n",
      "6\n",
      "14\n",
      "4\n",
      "13\n",
      "14\n",
      "8\n",
      "12\n",
      "14\n",
      "4\n",
      "11\n",
      "14\n",
      "10\n",
      "6\n",
      "37\n",
      "22\n",
      "27\n",
      "17\n",
      "24\n",
      "23\n",
      "2\n",
      "7\n",
      "22\n",
      "13\n",
      "14\n",
      "10\n",
      "8\n",
      "25\n",
      "38\n",
      "26\n",
      "36\n",
      "20\n",
      "19\n",
      "8\n",
      "11\n",
      "6\n",
      "8\n",
      "27\n",
      "31\n",
      "12\n",
      "7\n",
      "29\n",
      "33\n",
      "30\n",
      "39\n",
      "36\n",
      "17\n",
      "29\n",
      "38\n",
      "18\n",
      "2\n",
      "64\n",
      "77\n",
      "9\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "13\n",
      "7\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "6\n",
      "7\n",
      "10\n",
      "12\n",
      "2\n",
      "14\n",
      "9\n",
      "3\n",
      "10\n",
      "2\n",
      "16\n",
      "3\n",
      "9\n",
      "3\n",
      "15\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "3\n",
      "8\n",
      "13\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "2\n",
      "4\n",
      "5\n",
      "7\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "7\n",
      "4\n",
      "11\n",
      "8\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "10\n",
      "7\n",
      "4\n",
      "12\n",
      "13\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "8\n",
      "7\n",
      "4\n",
      "11\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "12\n",
      "7\n",
      "34\n",
      "36\n",
      "12\n",
      "39\n",
      "45\n",
      "25\n",
      "10\n",
      "6\n",
      "22\n",
      "7\n",
      "6\n",
      "9\n",
      "15\n",
      "5\n",
      "3\n",
      "12\n",
      "6\n",
      "32\n",
      "16\n",
      "26\n",
      "39\n",
      "21\n",
      "8\n",
      "6\n",
      "30\n",
      "19\n",
      "21\n",
      "38\n",
      "33\n",
      "21\n",
      "7\n",
      "9\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "13\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "6\n",
      "24\n",
      "45\n",
      "20\n",
      "19\n",
      "16\n",
      "33\n",
      "26\n",
      "38\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "dev_word_X = get_ner_sentences('eng.train')\n",
    "dev_word_X = get_word_emb_features(dev_word_X, 150)\n",
    "\n",
    "dev_char_X = get_ner_sentences('eng.testb')\n",
    "dev_char_X = get_char_emb_features(dev_char_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 The youth side replied with 246 for seven . \n",
      "2000 Unseeded Patrick Rafter recorded the most noteworthy result as he upset sixth-seeded American MaliVai Washington 6-2 6-1 in just 50 minutes . \n",
      "3000 Their release has been negotiated by Islamist writer Ismail Nacar as part of a wider effort , partly backed by Prime Minister Necmettin Erbakan , to find a political solution to Turkey 's Kurdish problem . \n",
      "4000 Lille 3 Rennes 1 \n",
      "5000 Waqar Younis not out 0 \n",
      "6000 Thai army commanders reject the explanation , saying they have evidence the Burmese army supplies and directs the renegade ethnic minority splinter faction . \n",
      "7000 But Stich did n't want to play that game . \n",
      "8000 - Fears of an Israeli operation causes the redistribution of Syrian troops locations in Lebanon . \n",
      "9000 But Meri , 67 , has been accused in parliament of taking too much power and not always consulting parliamentarians before making decisions . \n",
      "10000 Men 's 3,000 metres : \n",
      "11000 Austrian composer and organist , he wrote nine symphonies on a huge scale and three grand masses in the romantic tradition . \n",
      "12000 MOF 's Kubo says believes BOJ rate policy unchanged . \n",
      "13000 The tabloid Star magazine reported the married Morris had a lengthy affair with a $ 200-an-hour prostitute who he allowed to eavesdrop on telephone conversations with Clinton , and with whom he shared White House speeches before they were made . \n",
      "14000 for Sunday 's San Marino 500cc motorcycling Grand Prix : \n",
      "1000 Woman charged over N. Ireland arms find . \n",
      "2000 One of the dead was a civilian passer-by . \n",
      "3000 Chesterfield 21 11 4 6 22 16 37 \n",
      "12\n",
      "2\n",
      "12\n",
      "27\n",
      "27\n",
      "42\n",
      "23\n",
      "17\n",
      "18\n",
      "28\n",
      "38\n",
      "12\n",
      "31\n",
      "18\n",
      "21\n",
      "9\n",
      "17\n",
      "20\n",
      "1\n",
      "28\n",
      "17\n",
      "13\n",
      "11\n",
      "6\n",
      "4\n",
      "28\n",
      "38\n",
      "34\n",
      "29\n",
      "14\n",
      "15\n",
      "19\n",
      "13\n",
      "66\n",
      "10\n",
      "12\n",
      "23\n",
      "34\n",
      "11\n",
      "31\n",
      "15\n",
      "22\n",
      "21\n",
      "27\n",
      "19\n",
      "30\n",
      "71\n",
      "74\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "1\n",
      "9\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "1\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "12\n",
      "11\n",
      "10\n",
      "2\n",
      "12\n",
      "5\n",
      "4\n",
      "10\n",
      "9\n",
      "3\n",
      "13\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "5\n",
      "8\n",
      "4\n",
      "10\n",
      "3\n",
      "1\n",
      "10\n",
      "10\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "10\n",
      "38\n",
      "27\n",
      "33\n",
      "12\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "5\n",
      "9\n",
      "6\n",
      "6\n",
      "8\n",
      "11\n",
      "5\n",
      "8\n",
      "9\n",
      "25\n",
      "7\n",
      "19\n",
      "25\n",
      "31\n",
      "10\n",
      "8\n",
      "12\n",
      "9\n",
      "6\n",
      "6\n",
      "7\n",
      "4\n",
      "6\n",
      "6\n",
      "27\n",
      "33\n",
      "28\n",
      "23\n",
      "24\n",
      "14\n",
      "6\n",
      "35\n",
      "27\n",
      "29\n",
      "29\n",
      "29\n",
      "5\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "2\n",
      "8\n",
      "9\n",
      "10\n",
      "9\n",
      "8\n",
      "8\n",
      "2\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "2\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "2\n",
      "6\n",
      "21\n",
      "30\n",
      "30\n",
      "47\n",
      "38\n",
      "43\n",
      "39\n",
      "32\n",
      "37\n",
      "2\n",
      "124\n",
      "80\n",
      "8\n",
      "6\n",
      "56\n",
      "42\n",
      "12\n",
      "24\n",
      "23\n",
      "9\n",
      "9\n",
      "6\n",
      "25\n",
      "32\n",
      "27\n",
      "16\n",
      "29\n",
      "25\n",
      "2\n",
      "8\n",
      "23\n",
      "23\n",
      "14\n",
      "1\n",
      "6\n",
      "8\n",
      "3\n",
      "10\n",
      "4\n",
      "5\n",
      "8\n",
      "2\n",
      "6\n",
      "28\n",
      "22\n",
      "43\n",
      "27\n",
      "30\n",
      "24\n",
      "25\n",
      "15\n",
      "23\n",
      "25\n",
      "27\n",
      "29\n",
      "21\n",
      "10\n",
      "6\n",
      "5\n",
      "11\n",
      "2\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "28\n",
      "4\n",
      "23\n",
      "30\n",
      "10\n",
      "1\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "10\n",
      "20\n",
      "16\n",
      "27\n",
      "26\n",
      "11\n",
      "8\n",
      "10\n",
      "6\n",
      "22\n",
      "31\n",
      "13\n",
      "6\n",
      "22\n",
      "6\n",
      "8\n",
      "23\n",
      "24\n",
      "9\n",
      "6\n",
      "36\n",
      "35\n",
      "34\n",
      "30\n",
      "17\n",
      "18\n",
      "20\n",
      "34\n",
      "11\n",
      "39\n",
      "35\n",
      "17\n",
      "26\n",
      "18\n",
      "11\n",
      "6\n",
      "33\n",
      "2\n",
      "43\n",
      "44\n",
      "7\n",
      "6\n",
      "17\n",
      "3\n",
      "2\n",
      "18\n",
      "19\n",
      "21\n",
      "2\n",
      "17\n",
      "18\n",
      "2\n",
      "22\n",
      "17\n",
      "13\n",
      "14\n",
      "3\n",
      "3\n",
      "2\n",
      "17\n",
      "2\n",
      "16\n",
      "2\n",
      "17\n",
      "2\n",
      "18\n",
      "30\n",
      "11\n",
      "6\n",
      "37\n",
      "2\n",
      "12\n",
      "8\n",
      "10\n",
      "7\n",
      "4\n",
      "10\n",
      "15\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "8\n",
      "5\n",
      "7\n",
      "21\n",
      "1\n",
      "4\n",
      "11\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "13\n",
      "6\n",
      "35\n",
      "46\n",
      "33\n",
      "10\n",
      "13\n",
      "31\n",
      "23\n",
      "22\n",
      "26\n",
      "15\n",
      "15\n",
      "39\n",
      "33\n",
      "14\n",
      "27\n",
      "9\n",
      "7\n",
      "3\n",
      "8\n",
      "13\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "7\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "10\n",
      "7\n",
      "3\n",
      "12\n",
      "9\n",
      "3\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "2\n",
      "5\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "3\n",
      "2\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "2\n",
      "5\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "8\n",
      "7\n",
      "4\n",
      "11\n",
      "4\n",
      "14\n",
      "6\n",
      "35\n",
      "25\n",
      "21\n",
      "18\n",
      "27\n",
      "38\n",
      "9\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "13\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "13\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "14\n",
      "8\n",
      "5\n",
      "2\n",
      "2\n",
      "14\n",
      "7\n",
      "4\n",
      "2\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "15\n",
      "6\n",
      "5\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "12\n",
      "12\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "7\n",
      "6\n",
      "12\n",
      "21\n",
      "5\n",
      "3\n",
      "15\n",
      "5\n",
      "2\n",
      "15\n",
      "5\n",
      "2\n",
      "12\n",
      "5\n",
      "2\n",
      "10\n",
      "8\n",
      "34\n",
      "20\n",
      "11\n",
      "6\n",
      "46\n",
      "26\n",
      "29\n",
      "8\n",
      "2\n",
      "16\n",
      "59\n",
      "36\n",
      "38\n",
      "10\n",
      "6\n",
      "6\n",
      "10\n",
      "13\n",
      "5\n",
      "3\n",
      "7\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "1\n",
      "10\n",
      "9\n",
      "1\n",
      "8\n",
      "1\n",
      "10\n",
      "1\n",
      "9\n",
      "1\n",
      "8\n",
      "1\n",
      "10\n",
      "9\n",
      "1\n",
      "10\n",
      "3\n",
      "2\n",
      "11\n",
      "6\n",
      "36\n",
      "21\n",
      "21\n",
      "7\n",
      "6\n",
      "5\n",
      "8\n",
      "15\n",
      "5\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "6\n",
      "26\n",
      "7\n",
      "20\n",
      "9\n",
      "6\n",
      "33\n",
      "31\n",
      "26\n",
      "19\n",
      "38\n",
      "20\n",
      "20\n",
      "14\n",
      "11\n",
      "23\n",
      "20\n",
      "11\n",
      "9\n",
      "6\n",
      "24\n",
      "22\n",
      "11\n",
      "9\n",
      "29\n",
      "7\n",
      "9\n",
      "6\n",
      "22\n",
      "10\n",
      "18\n",
      "40\n",
      "10\n",
      "27\n",
      "14\n",
      "10\n",
      "46\n",
      "11\n",
      "26\n",
      "39\n",
      "11\n",
      "6\n",
      "21\n",
      "21\n",
      "17\n",
      "10\n",
      "24\n",
      "19\n",
      "10\n",
      "39\n",
      "21\n",
      "11\n",
      "10\n",
      "26\n",
      "26\n",
      "10\n",
      "13\n",
      "34\n",
      "16\n",
      "5\n",
      "6\n",
      "9\n",
      "2\n",
      "3\n",
      "16\n",
      "3\n",
      "13\n",
      "13\n",
      "2\n",
      "3\n",
      "18\n",
      "3\n",
      "5\n",
      "5\n",
      "11\n",
      "8\n",
      "43\n",
      "18\n",
      "27\n",
      "20\n",
      "11\n",
      "7\n",
      "8\n",
      "12\n",
      "41\n",
      "9\n",
      "9\n",
      "9\n",
      "26\n",
      "47\n",
      "21\n",
      "23\n",
      "18\n",
      "6\n",
      "42\n",
      "39\n",
      "32\n",
      "8\n",
      "2\n",
      "6\n",
      "30\n",
      "35\n",
      "10\n",
      "19\n",
      "14\n",
      "42\n",
      "18\n",
      "32\n",
      "23\n",
      "39\n",
      "4\n",
      "43\n",
      "19\n",
      "44\n",
      "8\n",
      "6\n",
      "5\n",
      "29\n",
      "9\n",
      "26\n",
      "21\n",
      "22\n",
      "7\n",
      "11\n",
      "6\n",
      "38\n",
      "20\n",
      "20\n",
      "50\n",
      "17\n",
      "36\n",
      "38\n",
      "30\n",
      "22\n",
      "37\n",
      "10\n",
      "10\n",
      "2\n",
      "6\n",
      "38\n",
      "30\n",
      "17\n",
      "22\n",
      "50\n",
      "24\n",
      "40\n",
      "27\n",
      "26\n",
      "27\n",
      "23\n",
      "20\n",
      "31\n",
      "45\n",
      "17\n",
      "10\n",
      "2\n",
      "6\n",
      "41\n",
      "55\n",
      "28\n",
      "7\n",
      "38\n",
      "42\n",
      "35\n",
      "43\n",
      "15\n",
      "55\n",
      "29\n",
      "14\n",
      "38\n",
      "41\n",
      "31\n",
      "22\n",
      "44\n",
      "35\n",
      "35\n",
      "41\n",
      "8\n",
      "7\n",
      "6\n",
      "28\n",
      "33\n",
      "23\n",
      "23\n",
      "12\n",
      "21\n",
      "26\n",
      "27\n",
      "13\n",
      "6\n",
      "42\n",
      "24\n",
      "14\n",
      "10\n",
      "8\n",
      "6\n",
      "14\n",
      "18\n",
      "8\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "15\n",
      "18\n",
      "9\n",
      "15\n",
      "8\n",
      "6\n",
      "26\n",
      "20\n",
      "30\n",
      "8\n",
      "6\n",
      "32\n",
      "8\n",
      "2\n",
      "6\n",
      "39\n",
      "50\n",
      "24\n",
      "55\n",
      "21\n",
      "29\n",
      "26\n",
      "21\n",
      "22\n",
      "29\n",
      "21\n",
      "59\n",
      "15\n",
      "35\n",
      "18\n",
      "10\n",
      "6\n",
      "23\n",
      "18\n",
      "26\n",
      "15\n",
      "30\n",
      "20\n",
      "17\n",
      "24\n",
      "36\n",
      "29\n",
      "17\n",
      "18\n",
      "30\n",
      "6\n",
      "6\n",
      "36\n",
      "25\n",
      "20\n",
      "14\n",
      "20\n",
      "16\n",
      "16\n",
      "19\n",
      "19\n",
      "23\n",
      "7\n",
      "36\n",
      "9\n",
      "6\n",
      "42\n",
      "20\n",
      "19\n",
      "18\n",
      "38\n",
      "23\n",
      "49\n",
      "10\n",
      "7\n",
      "6\n",
      "29\n",
      "18\n",
      "37\n",
      "18\n",
      "17\n",
      "10\n",
      "13\n",
      "6\n",
      "25\n",
      "20\n",
      "11\n",
      "9\n",
      "10\n",
      "8\n",
      "27\n",
      "10\n",
      "10\n",
      "6\n",
      "23\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "12\n",
      "3\n",
      "11\n",
      "8\n",
      "5\n",
      "11\n",
      "8\n",
      "6\n",
      "24\n",
      "13\n",
      "14\n",
      "17\n",
      "3\n",
      "3\n",
      "4\n",
      "10\n",
      "8\n",
      "7\n",
      "8\n",
      "10\n",
      "12\n",
      "7\n",
      "21\n",
      "10\n",
      "9\n",
      "7\n",
      "2\n",
      "3\n",
      "9\n",
      "11\n",
      "9\n",
      "7\n",
      "5\n",
      "12\n",
      "2\n",
      "11\n",
      "10\n",
      "9\n",
      "10\n",
      "10\n",
      "7\n",
      "31\n",
      "47\n",
      "32\n",
      "45\n",
      "35\n",
      "16\n",
      "17\n",
      "9\n",
      "8\n",
      "7\n",
      "30\n",
      "2\n",
      "8\n",
      "2\n",
      "7\n",
      "31\n",
      "23\n",
      "40\n",
      "16\n",
      "30\n",
      "22\n",
      "33\n",
      "35\n",
      "35\n",
      "34\n",
      "17\n",
      "21\n",
      "21\n",
      "29\n",
      "28\n",
      "40\n",
      "26\n",
      "30\n",
      "28\n",
      "19\n",
      "23\n",
      "26\n",
      "45\n",
      "35\n",
      "11\n",
      "8\n",
      "8\n",
      "26\n",
      "30\n",
      "5\n",
      "6\n",
      "22\n",
      "11\n",
      "21\n",
      "8\n",
      "2\n",
      "6\n",
      "37\n",
      "45\n",
      "48\n",
      "39\n",
      "31\n",
      "28\n",
      "21\n",
      "28\n",
      "46\n",
      "21\n",
      "30\n",
      "51\n",
      "17\n",
      "26\n",
      "15\n",
      "18\n",
      "15\n",
      "20\n",
      "33\n",
      "18\n",
      "11\n",
      "17\n",
      "20\n",
      "50\n",
      "39\n",
      "23\n",
      "6\n",
      "7\n",
      "13\n",
      "45\n",
      "21\n",
      "26\n",
      "17\n",
      "15\n",
      "8\n",
      "6\n",
      "35\n",
      "28\n",
      "8\n",
      "6\n",
      "26\n",
      "33\n",
      "21\n",
      "21\n",
      "17\n",
      "23\n",
      "11\n",
      "2\n",
      "6\n",
      "34\n",
      "35\n",
      "33\n",
      "23\n",
      "38\n",
      "31\n",
      "15\n",
      "24\n",
      "32\n",
      "26\n",
      "22\n",
      "9\n",
      "21\n",
      "23\n",
      "9\n",
      "25\n",
      "37\n",
      "9\n",
      "12\n",
      "17\n",
      "14\n",
      "25\n",
      "19\n",
      "19\n",
      "18\n",
      "32\n",
      "21\n",
      "26\n",
      "9\n",
      "6\n",
      "33\n",
      "9\n",
      "17\n",
      "10\n",
      "6\n",
      "24\n",
      "7\n",
      "7\n",
      "6\n",
      "31\n",
      "26\n",
      "16\n",
      "8\n",
      "20\n",
      "16\n",
      "7\n",
      "8\n",
      "6\n",
      "34\n",
      "34\n",
      "16\n",
      "31\n",
      "23\n",
      "21\n",
      "9\n",
      "6\n",
      "37\n",
      "15\n",
      "17\n",
      "33\n",
      "1\n",
      "42\n",
      "37\n",
      "29\n",
      "10\n",
      "2\n",
      "6\n",
      "38\n",
      "34\n",
      "14\n",
      "34\n",
      "35\n",
      "29\n",
      "62\n",
      "32\n",
      "10\n",
      "43\n",
      "6\n",
      "42\n",
      "21\n",
      "20\n",
      "23\n",
      "31\n",
      "28\n",
      "26\n",
      "12\n",
      "27\n",
      "20\n",
      "30\n",
      "8\n",
      "9\n",
      "6\n",
      "28\n",
      "16\n",
      "17\n",
      "14\n",
      "24\n",
      "8\n",
      "8\n",
      "6\n",
      "25\n",
      "26\n",
      "15\n",
      "20\n",
      "14\n",
      "27\n",
      "38\n",
      "35\n",
      "11\n",
      "6\n",
      "38\n",
      "35\n",
      "22\n",
      "22\n",
      "32\n",
      "31\n",
      "27\n",
      "9\n",
      "6\n",
      "32\n",
      "39\n",
      "47\n",
      "14\n",
      "33\n",
      "21\n",
      "11\n",
      "8\n",
      "6\n",
      "26\n",
      "19\n",
      "21\n",
      "17\n",
      "7\n",
      "18\n",
      "13\n",
      "6\n",
      "25\n",
      "22\n",
      "11\n",
      "20\n",
      "19\n",
      "11\n",
      "18\n",
      "12\n",
      "10\n",
      "2\n",
      "20\n",
      "7\n",
      "49\n",
      "18\n",
      "9\n",
      "32\n",
      "20\n",
      "21\n",
      "17\n",
      "31\n",
      "16\n",
      "11\n",
      "21\n",
      "23\n",
      "20\n",
      "15\n",
      "14\n",
      "9\n",
      "16\n",
      "28\n",
      "7\n",
      "3\n",
      "8\n",
      "42\n",
      "46\n",
      "26\n",
      "31\n",
      "12\n",
      "19\n",
      "26\n",
      "25\n",
      "25\n",
      "19\n",
      "23\n",
      "31\n",
      "25\n",
      "39\n",
      "33\n",
      "31\n",
      "11\n",
      "31\n",
      "19\n",
      "8\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "8\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "10\n",
      "7\n",
      "24\n",
      "35\n",
      "19\n",
      "4\n",
      "22\n",
      "23\n",
      "37\n",
      "5\n",
      "22\n",
      "23\n",
      "3\n",
      "14\n",
      "17\n",
      "12\n",
      "10\n",
      "8\n",
      "29\n",
      "36\n",
      "16\n",
      "10\n",
      "6\n",
      "26\n",
      "29\n",
      "16\n",
      "44\n",
      "21\n",
      "20\n",
      "17\n",
      "31\n",
      "15\n",
      "9\n",
      "9\n",
      "31\n",
      "17\n",
      "12\n",
      "29\n",
      "37\n",
      "21\n",
      "20\n",
      "30\n",
      "18\n",
      "38\n",
      "10\n",
      "24\n",
      "35\n",
      "33\n",
      "31\n",
      "10\n",
      "6\n",
      "33\n",
      "17\n",
      "33\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "32\n",
      "38\n",
      "23\n",
      "33\n",
      "31\n",
      "16\n",
      "14\n",
      "8\n",
      "2\n",
      "6\n",
      "39\n",
      "22\n",
      "5\n",
      "24\n",
      "19\n",
      "18\n",
      "5\n",
      "37\n",
      "30\n",
      "9\n",
      "20\n",
      "29\n",
      "6\n",
      "31\n",
      "33\n",
      "10\n",
      "15\n",
      "27\n",
      "27\n",
      "22\n",
      "33\n",
      "17\n",
      "13\n",
      "20\n",
      "10\n",
      "6\n",
      "33\n",
      "53\n",
      "37\n",
      "42\n",
      "19\n",
      "17\n",
      "32\n",
      "35\n",
      "43\n",
      "17\n",
      "38\n",
      "32\n",
      "28\n",
      "7\n",
      "6\n",
      "38\n",
      "34\n",
      "23\n",
      "33\n",
      "22\n",
      "27\n",
      "17\n",
      "21\n",
      "44\n",
      "33\n",
      "8\n",
      "10\n",
      "2\n",
      "6\n",
      "38\n",
      "45\n",
      "41\n",
      "33\n",
      "36\n",
      "30\n",
      "10\n",
      "18\n",
      "19\n",
      "50\n",
      "43\n",
      "28\n",
      "21\n",
      "29\n",
      "53\n",
      "48\n",
      "22\n",
      "19\n",
      "30\n",
      "18\n",
      "48\n",
      "15\n",
      "9\n",
      "2\n",
      "6\n",
      "25\n",
      "29\n",
      "40\n",
      "30\n",
      "19\n",
      "53\n",
      "23\n",
      "28\n",
      "29\n",
      "24\n",
      "28\n",
      "35\n",
      "38\n",
      "35\n",
      "31\n",
      "14\n",
      "6\n",
      "12\n",
      "11\n",
      "5\n",
      "18\n",
      "18\n",
      "15\n",
      "15\n",
      "11\n",
      "9\n",
      "10\n",
      "9\n",
      "3\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "7\n",
      "8\n",
      "9\n",
      "23\n",
      "9\n",
      "3\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "11\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "3\n",
      "2\n",
      "7\n",
      "10\n",
      "10\n",
      "8\n",
      "21\n",
      "14\n",
      "37\n",
      "41\n",
      "32\n",
      "54\n",
      "27\n",
      "27\n",
      "14\n",
      "18\n",
      "19\n",
      "28\n",
      "17\n",
      "16\n",
      "7\n",
      "9\n",
      "7\n",
      "17\n",
      "10\n",
      "14\n",
      "7\n",
      "16\n",
      "3\n",
      "6\n",
      "3\n",
      "11\n",
      "11\n",
      "17\n",
      "11\n",
      "20\n",
      "28\n",
      "11\n",
      "11\n",
      "13\n",
      "11\n",
      "11\n",
      "4\n",
      "5\n",
      "32\n",
      "32\n",
      "7\n",
      "30\n",
      "28\n",
      "26\n",
      "15\n",
      "5\n",
      "19\n",
      "4\n",
      "4\n",
      "11\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "10\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "21\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "36\n",
      "22\n",
      "9\n",
      "6\n",
      "7\n",
      "26\n",
      "27\n",
      "25\n",
      "19\n",
      "12\n",
      "17\n",
      "26\n",
      "18\n",
      "19\n",
      "43\n",
      "15\n",
      "23\n",
      "25\n",
      "19\n",
      "17\n",
      "29\n",
      "14\n",
      "8\n",
      "8\n",
      "16\n",
      "8\n",
      "20\n",
      "24\n",
      "23\n",
      "28\n",
      "25\n",
      "32\n",
      "7\n",
      "8\n",
      "6\n",
      "27\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "11\n",
      "10\n",
      "6\n",
      "25\n",
      "40\n",
      "20\n",
      "21\n",
      "15\n",
      "6\n",
      "4\n",
      "5\n",
      "30\n",
      "28\n",
      "22\n",
      "10\n",
      "6\n",
      "33\n",
      "32\n",
      "39\n",
      "15\n",
      "11\n",
      "10\n",
      "20\n",
      "18\n",
      "43\n",
      "23\n",
      "25\n",
      "16\n",
      "13\n",
      "33\n",
      "11\n",
      "7\n",
      "16\n",
      "6\n",
      "6\n",
      "11\n",
      "7\n",
      "6\n",
      "9\n",
      "3\n",
      "4\n",
      "2\n",
      "10\n",
      "16\n",
      "7\n",
      "22\n",
      "18\n",
      "10\n",
      "2\n",
      "7\n",
      "35\n",
      "75\n",
      "39\n",
      "11\n",
      "31\n",
      "32\n",
      "17\n",
      "23\n",
      "39\n",
      "33\n",
      "10\n",
      "6\n",
      "31\n",
      "29\n",
      "18\n",
      "19\n",
      "9\n",
      "6\n",
      "37\n",
      "35\n",
      "18\n",
      "36\n",
      "19\n",
      "25\n",
      "48\n",
      "8\n",
      "8\n",
      "31\n",
      "34\n",
      "7\n",
      "6\n",
      "27\n",
      "18\n",
      "6\n",
      "9\n",
      "6\n",
      "23\n",
      "41\n",
      "18\n",
      "32\n",
      "31\n",
      "25\n",
      "14\n",
      "8\n",
      "7\n",
      "38\n",
      "42\n",
      "9\n",
      "22\n",
      "30\n",
      "27\n",
      "29\n",
      "18\n",
      "11\n",
      "7\n",
      "28\n",
      "10\n",
      "4\n",
      "6\n",
      "6\n",
      "11\n",
      "9\n",
      "6\n",
      "31\n",
      "21\n",
      "15\n",
      "6\n",
      "6\n",
      "33\n",
      "24\n",
      "24\n",
      "7\n",
      "6\n",
      "30\n",
      "15\n",
      "13\n",
      "8\n",
      "9\n",
      "10\n",
      "6\n",
      "23\n",
      "31\n",
      "13\n",
      "15\n",
      "8\n",
      "14\n",
      "26\n",
      "24\n",
      "23\n",
      "35\n",
      "18\n",
      "13\n",
      "27\n",
      "22\n",
      "17\n",
      "10\n",
      "10\n",
      "8\n",
      "6\n",
      "35\n",
      "37\n",
      "8\n",
      "9\n",
      "6\n",
      "35\n",
      "15\n",
      "25\n",
      "9\n",
      "29\n",
      "11\n",
      "9\n",
      "8\n",
      "31\n",
      "32\n",
      "47\n",
      "15\n",
      "20\n",
      "12\n",
      "28\n",
      "10\n",
      "11\n",
      "9\n",
      "6\n",
      "41\n",
      "16\n",
      "25\n",
      "10\n",
      "8\n",
      "24\n",
      "25\n",
      "21\n",
      "15\n",
      "10\n",
      "17\n",
      "19\n",
      "44\n",
      "24\n",
      "25\n",
      "23\n",
      "20\n",
      "9\n",
      "6\n",
      "38\n",
      "32\n",
      "20\n",
      "16\n",
      "25\n",
      "21\n",
      "19\n",
      "10\n",
      "17\n",
      "6\n",
      "15\n",
      "13\n",
      "10\n",
      "8\n",
      "30\n",
      "33\n",
      "11\n",
      "11\n",
      "38\n",
      "25\n",
      "28\n",
      "10\n",
      "6\n",
      "9\n",
      "8\n",
      "7\n",
      "2\n",
      "8\n",
      "10\n",
      "28\n",
      "15\n",
      "12\n",
      "7\n",
      "7\n",
      "3\n",
      "14\n",
      "2\n",
      "8\n",
      "10\n",
      "6\n",
      "12\n",
      "17\n",
      "13\n",
      "13\n",
      "7\n",
      "9\n",
      "4\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "10\n",
      "9\n",
      "7\n",
      "30\n",
      "15\n",
      "28\n",
      "27\n",
      "10\n",
      "28\n",
      "19\n",
      "13\n",
      "12\n",
      "7\n",
      "6\n",
      "37\n",
      "18\n",
      "29\n",
      "13\n",
      "26\n",
      "13\n",
      "23\n",
      "20\n",
      "39\n",
      "37\n",
      "11\n",
      "39\n",
      "26\n",
      "57\n",
      "8\n",
      "8\n",
      "33\n",
      "37\n",
      "14\n",
      "28\n",
      "42\n",
      "6\n",
      "2\n",
      "6\n",
      "33\n",
      "31\n",
      "34\n",
      "29\n",
      "28\n",
      "11\n",
      "44\n",
      "12\n",
      "5\n",
      "9\n",
      "35\n",
      "10\n",
      "11\n",
      "32\n",
      "26\n",
      "31\n",
      "17\n",
      "31\n",
      "15\n",
      "25\n",
      "8\n",
      "12\n",
      "19\n",
      "20\n",
      "48\n",
      "10\n",
      "8\n",
      "13\n",
      "16\n",
      "16\n",
      "33\n",
      "27\n",
      "26\n",
      "8\n",
      "9\n",
      "6\n",
      "31\n",
      "38\n",
      "27\n",
      "32\n",
      "8\n",
      "6\n",
      "37\n",
      "15\n",
      "28\n",
      "30\n",
      "30\n",
      "8\n",
      "8\n",
      "30\n",
      "47\n",
      "12\n",
      "14\n",
      "27\n",
      "15\n",
      "31\n",
      "24\n",
      "28\n",
      "32\n",
      "35\n",
      "8\n",
      "6\n",
      "23\n",
      "28\n",
      "31\n",
      "10\n",
      "8\n",
      "6\n",
      "20\n",
      "29\n",
      "10\n",
      "6\n",
      "33\n",
      "33\n",
      "26\n",
      "26\n",
      "8\n",
      "29\n",
      "23\n",
      "6\n",
      "7\n",
      "34\n",
      "8\n",
      "6\n",
      "34\n",
      "24\n",
      "36\n",
      "12\n",
      "9\n",
      "7\n",
      "8\n",
      "31\n",
      "22\n",
      "12\n",
      "37\n",
      "23\n",
      "8\n",
      "9\n",
      "6\n",
      "34\n",
      "38\n",
      "25\n",
      "7\n",
      "6\n",
      "6\n",
      "18\n",
      "6\n",
      "11\n",
      "6\n",
      "28\n",
      "19\n",
      "25\n",
      "10\n",
      "9\n",
      "6\n",
      "19\n",
      "14\n",
      "9\n",
      "9\n",
      "8\n",
      "11\n",
      "6\n",
      "37\n",
      "36\n",
      "9\n",
      "17\n",
      "5\n",
      "6\n",
      "16\n",
      "45\n",
      "28\n",
      "17\n",
      "22\n",
      "22\n",
      "10\n",
      "6\n",
      "33\n",
      "40\n",
      "34\n",
      "24\n",
      "34\n",
      "8\n",
      "33\n",
      "9\n",
      "21\n",
      "5\n",
      "23\n",
      "6\n",
      "6\n",
      "23\n",
      "46\n",
      "24\n",
      "23\n",
      "32\n",
      "38\n",
      "12\n",
      "12\n",
      "6\n",
      "33\n",
      "12\n",
      "12\n",
      "6\n",
      "25\n",
      "21\n",
      "18\n",
      "24\n",
      "9\n",
      "6\n",
      "26\n",
      "46\n",
      "15\n",
      "33\n",
      "29\n",
      "19\n",
      "28\n",
      "20\n",
      "9\n",
      "8\n",
      "6\n",
      "43\n",
      "20\n",
      "37\n",
      "28\n",
      "5\n",
      "30\n",
      "34\n",
      "10\n",
      "6\n",
      "17\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "8\n",
      "6\n",
      "45\n",
      "18\n",
      "24\n",
      "9\n",
      "6\n",
      "22\n",
      "14\n",
      "7\n",
      "36\n",
      "26\n",
      "10\n",
      "6\n",
      "28\n",
      "41\n",
      "35\n",
      "21\n",
      "9\n",
      "6\n",
      "38\n",
      "27\n",
      "43\n",
      "16\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "2\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "12\n",
      "11\n",
      "2\n",
      "6\n",
      "40\n",
      "26\n",
      "34\n",
      "38\n",
      "42\n",
      "30\n",
      "31\n",
      "33\n",
      "21\n",
      "7\n",
      "22\n",
      "33\n",
      "26\n",
      "35\n",
      "20\n",
      "33\n",
      "10\n",
      "15\n",
      "30\n",
      "47\n",
      "42\n",
      "6\n",
      "6\n",
      "30\n",
      "26\n",
      "20\n",
      "9\n",
      "2\n",
      "6\n",
      "40\n",
      "33\n",
      "33\n",
      "32\n",
      "43\n",
      "6\n",
      "10\n",
      "51\n",
      "47\n",
      "38\n",
      "33\n",
      "22\n",
      "39\n",
      "37\n",
      "21\n",
      "40\n",
      "23\n",
      "38\n",
      "25\n",
      "18\n",
      "19\n",
      "10\n",
      "6\n",
      "41\n",
      "20\n",
      "25\n",
      "38\n",
      "27\n",
      "20\n",
      "13\n",
      "23\n",
      "7\n",
      "8\n",
      "30\n",
      "21\n",
      "21\n",
      "37\n",
      "34\n",
      "16\n",
      "15\n",
      "12\n",
      "8\n",
      "15\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "29\n",
      "11\n",
      "8\n",
      "3\n",
      "10\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "9\n",
      "8\n",
      "6\n",
      "10\n",
      "8\n",
      "16\n",
      "20\n",
      "10\n",
      "9\n",
      "22\n",
      "19\n",
      "29\n",
      "31\n",
      "20\n",
      "18\n",
      "9\n",
      "8\n",
      "14\n",
      "4\n",
      "3\n",
      "3\n",
      "22\n",
      "33\n",
      "9\n",
      "8\n",
      "4\n",
      "7\n",
      "2\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "4\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "10\n",
      "8\n",
      "3\n",
      "9\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "4\n",
      "5\n",
      "4\n",
      "14\n",
      "2\n",
      "11\n",
      "12\n",
      "11\n",
      "11\n",
      "3\n",
      "8\n",
      "8\n",
      "5\n",
      "4\n",
      "11\n",
      "11\n",
      "12\n",
      "15\n",
      "11\n",
      "3\n",
      "4\n",
      "4\n",
      "8\n",
      "9\n",
      "8\n",
      "20\n",
      "14\n",
      "10\n",
      "8\n",
      "21\n",
      "34\n",
      "26\n",
      "33\n",
      "29\n",
      "25\n",
      "9\n",
      "8\n",
      "25\n",
      "38\n",
      "13\n",
      "21\n",
      "37\n",
      "34\n",
      "41\n",
      "25\n",
      "9\n",
      "8\n",
      "13\n",
      "13\n",
      "8\n",
      "12\n",
      "5\n",
      "12\n",
      "5\n",
      "12\n",
      "5\n",
      "12\n",
      "5\n",
      "12\n",
      "5\n",
      "12\n",
      "6\n",
      "12\n",
      "5\n",
      "14\n",
      "2\n",
      "3\n",
      "8\n",
      "11\n",
      "10\n",
      "3\n",
      "9\n",
      "8\n",
      "30\n",
      "25\n",
      "8\n",
      "23\n",
      "14\n",
      "21\n",
      "27\n",
      "14\n",
      "10\n",
      "15\n",
      "29\n",
      "17\n",
      "21\n",
      "24\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "2\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "10\n",
      "8\n",
      "4\n",
      "13\n",
      "12\n",
      "6\n",
      "13\n",
      "13\n",
      "13\n",
      "15\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "10\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "4\n",
      "4\n",
      "8\n",
      "8\n",
      "9\n",
      "2\n",
      "10\n",
      "3\n",
      "17\n",
      "18\n",
      "3\n",
      "14\n",
      "3\n",
      "17\n",
      "11\n",
      "9\n",
      "16\n",
      "9\n",
      "10\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "7\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "8\n",
      "9\n",
      "11\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "9\n",
      "31\n",
      "33\n",
      "21\n",
      "26\n",
      "33\n",
      "25\n",
      "8\n",
      "6\n",
      "4\n",
      "8\n",
      "14\n",
      "7\n",
      "13\n",
      "14\n",
      "8\n",
      "3\n",
      "11\n",
      "11\n",
      "13\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "7\n",
      "10\n",
      "3\n",
      "13\n",
      "15\n",
      "5\n",
      "13\n",
      "15\n",
      "4\n",
      "13\n",
      "8\n",
      "10\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "15\n",
      "6\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "7\n",
      "6\n",
      "10\n",
      "22\n",
      "5\n",
      "3\n",
      "5\n",
      "1\n",
      "12\n",
      "4\n",
      "1\n",
      "16\n",
      "4\n",
      "1\n",
      "26\n",
      "4\n",
      "2\n",
      "9\n",
      "6\n",
      "26\n",
      "42\n",
      "26\n",
      "18\n",
      "21\n",
      "16\n",
      "30\n",
      "7\n",
      "6\n",
      "4\n",
      "5\n",
      "16\n",
      "3\n",
      "5\n",
      "3\n",
      "15\n",
      "4\n",
      "4\n",
      "1\n",
      "16\n",
      "4\n",
      "1\n",
      "13\n",
      "4\n",
      "1\n",
      "10\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "10\n",
      "4\n",
      "1\n",
      "15\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "6\n",
      "4\n",
      "15\n",
      "8\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "9\n",
      "6\n",
      "6\n",
      "5\n",
      "15\n",
      "9\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "2\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "2\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "6\n",
      "29\n",
      "47\n",
      "25\n",
      "28\n",
      "31\n",
      "8\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "6\n",
      "11\n",
      "12\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "12\n",
      "4\n",
      "4\n",
      "5\n",
      "14\n",
      "3\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "7\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "12\n",
      "6\n",
      "29\n",
      "40\n",
      "34\n",
      "21\n",
      "21\n",
      "10\n",
      "6\n",
      "24\n",
      "2\n",
      "19\n",
      "7\n",
      "7\n",
      "10\n",
      "5\n",
      "8\n",
      "6\n",
      "6\n",
      "11\n",
      "9\n",
      "6\n",
      "9\n",
      "12\n",
      "9\n",
      "7\n",
      "6\n",
      "14\n",
      "4\n",
      "13\n",
      "14\n",
      "8\n",
      "12\n",
      "14\n",
      "4\n",
      "11\n",
      "14\n",
      "10\n",
      "6\n",
      "37\n",
      "22\n",
      "27\n",
      "17\n",
      "24\n",
      "23\n",
      "2\n",
      "7\n",
      "22\n",
      "13\n",
      "14\n",
      "10\n",
      "8\n",
      "25\n",
      "38\n",
      "26\n",
      "36\n",
      "20\n",
      "19\n",
      "8\n",
      "11\n",
      "6\n",
      "8\n",
      "27\n",
      "31\n",
      "12\n",
      "7\n",
      "29\n",
      "33\n",
      "30\n",
      "39\n",
      "36\n",
      "17\n",
      "29\n",
      "38\n",
      "18\n",
      "2\n",
      "64\n",
      "77\n",
      "9\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "13\n",
      "7\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "6\n",
      "7\n",
      "10\n",
      "12\n",
      "2\n",
      "14\n",
      "9\n",
      "3\n",
      "10\n",
      "2\n",
      "16\n",
      "3\n",
      "9\n",
      "3\n",
      "15\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "3\n",
      "8\n",
      "13\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "2\n",
      "4\n",
      "5\n",
      "7\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "7\n",
      "4\n",
      "11\n",
      "8\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "10\n",
      "7\n",
      "4\n",
      "12\n",
      "13\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "2\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "8\n",
      "7\n",
      "4\n",
      "11\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "12\n",
      "7\n",
      "34\n",
      "36\n",
      "12\n",
      "39\n",
      "45\n",
      "25\n",
      "10\n",
      "6\n",
      "22\n",
      "7\n",
      "6\n",
      "9\n",
      "15\n",
      "5\n",
      "3\n",
      "12\n",
      "6\n",
      "32\n",
      "16\n",
      "26\n",
      "39\n",
      "21\n",
      "8\n",
      "6\n",
      "30\n",
      "19\n",
      "21\n",
      "38\n",
      "33\n",
      "21\n",
      "7\n",
      "9\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "13\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "6\n",
      "24\n",
      "45\n",
      "20\n",
      "19\n",
      "16\n",
      "33\n",
      "26\n",
      "38\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "train_word_X = get_ner_sentences('eng.train')\n",
    "train_word_X = get_word_emb_features(train_word_X, 150)\n",
    "\n",
    "train_char_X = get_ner_sentences('eng.testb')\n",
    "train_char_X = get_char_emb_features(train_char_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embeddings = get_embeddings(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Woman charged over N. Ireland arms find . \n",
      "2000 One of the dead was a civilian passer-by . \n",
      "3000 Chesterfield 21 11 4 6 22 16 37 \n"
     ]
    }
   ],
   "source": [
    "dev_word_X = get_ner_sentences('eng.testb')\n",
    "dev_word_X = get_word_emb_features(dev_word_X, max_length_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "200 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "300 [u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "400 [u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ']\n",
      "500 [u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ']\n",
      "600 [u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "700 [u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ']\n",
      "800 [u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ']\n",
      "900 [u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1000 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1100 [u'I-LOC ', u'O ']\n",
      "1200 [u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1300 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1400 [u'I-MISC ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1500 [u'O ', u'I-LOC ', u'O ', u'O ', u'O ']\n",
      "1600 [u'O ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1700 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1800 [u'I-LOC ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1900 [u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "2000 [u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "2100 [u'I-ORG ', u'O ', u'I-LOC ']\n",
      "2200 [u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "2300 [u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'I-MISC ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'I-PER ', u'I-PER ', u'O ']\n",
      "2400 [u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'O ']\n",
      "2500 [u'O ', u'O ']\n",
      "2600 [u'O ', u'I-MISC ', u'O ', u'I-MISC ', u'O ']\n",
      "2700 [u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'I-MISC ', u'O ']\n",
      "2800 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "2900 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "3000 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'I-MISC ', u'O ', u'O ']\n",
      "3100 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ']\n",
      "3200 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "3300 [u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "3400 [u'O ', u'O ', u'O ', u'O ']\n",
      "3500 [u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ']\n",
      "3600 [u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ']\n",
      "3700 [u'I-ORG ', u'O ', u'I-ORG ', u'O ']\n",
      "3800 [u'I-LOC ', u'O ']\n",
      "3900 [u'I-ORG ', u'I-ORG ', u'O ', u'I-ORG ', u'I-ORG ', u'O ']\n",
      "4000 [u'I-ORG ', u'O ', u'I-ORG ', u'O ']\n",
      "4100 [u'I-ORG ', u'I-ORG ', u'O ', u'I-ORG ', u'I-ORG ', u'O ']\n",
      "4200 [u'I-ORG ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "4300 [u'I-LOC ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ']\n",
      "4400 [u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'O ']\n",
      "4500 [u'O ', u'O ']\n",
      "4600 [u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'I-ORG ']\n",
      "4700 [u'O ', u'O ', u'O ', u'O ']\n",
      "4800 [u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'I-MISC ', u'I-MISC ', u'O ']\n",
      "4900 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "5000 [u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ']\n",
      "5100 [u'O ', u'O ', u'O ', u'O ', u'I-MISC ']\n",
      "5200 [u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "5300 [u'O ', u'O ', u'O ']\n",
      "5400 [u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "5500 [u'O ', u'O ', u'I-MISC ', u'O ', u'O ']\n",
      "5600 [u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ']\n",
      "5700 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "5800 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "5900 [u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "6000 [u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "6100 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "6200 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "6300 [u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'O ']\n",
      "6400 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "6500 [u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ']\n",
      "6600 [u'I-LOC ', u'O ', u'O ', u'O ', u'O ']\n",
      "6700 [u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "6800 [u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ', u'I-ORG ', u'O ']\n",
      "6900 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "7000 [u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "7100 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ']\n",
      "7200 [u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ']\n",
      "7300 [u'O ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "7400 [u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "7500 [u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ']\n",
      "7600 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "7700 [u'I-PER ', u'I-PER ', u'O ']\n",
      "7800 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "7900 [u'O ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "8000 [u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ']\n",
      "8100 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ']\n",
      "8200 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "8300 [u'O ', u'O ', u'I-LOC ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ']\n",
      "8400 [u'O ', u'O ', u'O ']\n",
      "8500 [u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ']\n",
      "8600 [u'O ', u'O ', u'I-MISC ', u'I-MISC ', u'I-MISC ', u'O ']\n",
      "8700 [u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "8800 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ']\n",
      "8900 [u'O ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "9000 [u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "9100 [u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ']\n",
      "9200 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "9300 [u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'I-LOC ', u'O ']\n",
      "9400 [u'O ', u'O ', u'I-ORG ', u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "9500 [u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600 [u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "9700 [u'I-LOC ', u'O ']\n",
      "9800 [u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ']\n",
      "9900 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'O ']\n",
      "10000 [u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "10100 [u'O ', u'I-LOC ', u'O ', u'O ']\n",
      "10200 [u'I-LOC ', u'O ']\n",
      "10300 [u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ', u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ', u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ', u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "10400 [u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ']\n",
      "10500 [u'I-ORG ', u'O ', u'I-ORG ', u'O ']\n",
      "10600 [u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "10700 [u'O ', u'O ', u'O ']\n",
      "10800 [u'I-ORG ', u'I-ORG ', u'O ', u'I-ORG ', u'O ']\n",
      "10900 [u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "11000 [u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "11100 [u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "11200 [u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "11300 [u'O ', u'I-MISC ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "11400 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "11500 [u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ']\n",
      "11600 [u'I-LOC ', u'O ', u'I-LOC ', u'O ']\n",
      "11700 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "11800 [u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'O ']\n",
      "11900 [u'I-ORG ', u'I-ORG ']\n",
      "12000 [u'I-ORG ', u'O ', u'I-PER ', u'O ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ']\n",
      "12100 [u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ']\n",
      "12200 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "12300 [u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "12400 [u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'I-PER ', u'I-PER ', u'O ']\n",
      "12500 [u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "12600 [u'I-ORG ', u'O ', u'I-ORG ', u'O ']\n",
      "12700 [u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "12800 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "12900 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "13000 [u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "13100 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ']\n",
      "13200 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'I-LOC ', u'O ']\n",
      "13300 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "13400 [u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "13500 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "13600 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "13700 [u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "13800 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "13900 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ']\n",
      "14000 [u'O ', u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'I-MISC ', u'I-MISC ', u'O ']\n",
      "[u'I-LOC ', u'I-PER ', u'B-ORG ', u'I-ORG ', u'O ', u'B-LOC ', u'B-MISC ', u'I-MISC ']\n",
      "Labels >>>>>>>>>>>>>>>>>>>>>>>>>>> [u'LOC ', u'PER ', u'MISC ', u'ORG ', u'O ']\n",
      "{u'ORG ': 4, u'LOC ': 1, u'PER ': 2, u'MISC ': 3, u'O ': 5}\n",
      "100 [u'I-PER ', u'I-PER ', u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "200 [u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'I-LOC ', u'O ', u'I-LOC ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "300 [u'I-LOC ', u'O ']\n",
      "400 [u'I-ORG ', u'O ', u'I-LOC ']\n",
      "500 [u'O ', u'O ', u'O ', u'O ', u'I-ORG ']\n",
      "600 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "700 [u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-ORG ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'I-ORG ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-ORG ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-ORG ', u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ']\n",
      "800 [u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "900 [u'I-PER ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1000 [u'O ', u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ']\n",
      "1100 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1200 [u'O ', u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1300 [u'O ']\n",
      "1400 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ']\n",
      "1500 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1600 [u'O ', u'I-MISC ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'I-PER ', u'O ', u'O ', u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1700 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "1800 [u'I-LOC ', u'O ', u'I-LOC ', u'O ']\n",
      "1900 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "2000 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "2100 [u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "2200 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'O ']\n",
      "2300 [u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "2400 [u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'O ']\n",
      "2500 [u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-LOC ', u'O ', u'O ']\n",
      "2600 [u'O ', u'I-MISC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-LOC ', u'O ', u'I-LOC ', u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-MISC ', u'I-MISC ', u'O ', u'O ']\n",
      "2700 [u'O ', u'I-PER ', u'O ']\n",
      "2800 [u'O ', u'O ', u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "2900 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "3000 [u'I-ORG ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "3100 [u'I-ORG ', u'I-ORG ', u'O ', u'I-ORG ', u'O ']\n",
      "3200 [u'I-LOC ', u'I-LOC ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'I-PER ', u'O ']\n",
      "3300 [u'I-ORG ', u'O ', u'I-LOC ']\n",
      "3400 [u'I-ORG ', u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'I-PER ', u'I-PER ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'I-ORG ', u'O ', u'I-LOC ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ', u'O ']\n",
      "Labels >>>>>>>>>>>>>>>>>>>>>>>>>>> [u'LOC ', u'PER ', u'MISC ', u'ORG ', u'O ']\n",
      "{u'ORG ': 4, u'LOC ': 1, u'PER ': 2, u'MISC ': 3, u'O ': 5}\n"
     ]
    }
   ],
   "source": [
    "def get_ner_bio(filex):\n",
    "    sent_count = 0\n",
    "    sent = []\n",
    "    with io.open(filex, encoding='utf-8') as fl:\n",
    "        for line in fl:\n",
    "            line = line.strip()\n",
    "            toks = line.split()\n",
    "            #sentence break\n",
    "            if len(toks)<1:\n",
    "                if len(sent)>0:\n",
    "                    sent_count+=1\n",
    "                    if sent_count%100==0:\n",
    "                        print(sent_count, sent)\n",
    "                    res = sent\n",
    "                    sent = []                   \n",
    "                    yield res\n",
    "                    \n",
    "            #sentence start\n",
    "            elif toks[0]==u'-DOCSTART-':\n",
    "                sent=[]\n",
    "            else:\n",
    "                sent.append(toks[3]+' ')\n",
    "\n",
    "                \n",
    "def pad_hotencode_labels(train_labels, BIO_LABELS, max_length=150, bio=False):\n",
    "        \n",
    "    if bio:\n",
    "        LABELS = BIO_LABELS\n",
    "        ent2id = dict(zip(LABELS, 1+np.arange(len(LABELS))))\n",
    "        train_encids = [[ent2id[i] for i in ents_list] for ents_list in train_labels ]\n",
    "    else:\n",
    "        LABELS = list(set([i.split('-')[-1] for i in BIO_LABELS]))\n",
    "   \n",
    "        print('Labels >>>>>>>>>>>>>>>>>>>>>>>>>>>', LABELS)\n",
    "\n",
    "        ent2id_wo_BIO = dict(zip(LABELS, 1+np.arange(len(LABELS))))\n",
    "\n",
    "        print(ent2id_wo_BIO)\n",
    "        #train_encids = [[ent2id[i] for i in ents_list] for ents_list in train_labels ]\n",
    "        train_encids = [[ent2id_wo_BIO[i.split('-')[-1]] for i in ents_list] for ents_list in train_labels ]\n",
    "            \n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(np.arange(len(LABELS)+1).reshape(len(LABELS)+1,1))\n",
    "\n",
    "    Xs = np.zeros((len(train_labels), max_length), dtype='int32')\n",
    "\n",
    "    for i in range(len(train_encids)):\n",
    "        sent=train_encids[i]\n",
    "        for idx, enc in enumerate(sent):\n",
    "            #print(idx)\n",
    "            try:\n",
    "                Xs[i, idx]=enc\n",
    "            except:\n",
    "                print(sent)\n",
    "                \n",
    "    tr = Xs.reshape(Xs.shape[0], Xs.shape[1], 1)\n",
    "    tr_he = np.array([encoder.transform(tr[i,:,:]).toarray() for i in range(tr.shape[0])])\n",
    "    return tr_he\n",
    "\n",
    "train_labels = list(get_ner_bio('eng.train'))\n",
    "BIO_LABELS = list(set([i for sub_list in train_labels for i in sub_list]))\n",
    "print(BIO_LABELS)\n",
    "max_length_sent = 150\n",
    "\n",
    "LABELS = list(set([i.split('-')[-1] for i in BIO_LABELS]))\n",
    "train_labels = pad_hotencode_labels(train_labels, BIO_LABELS, max_length=max_length_sent)\n",
    "\n",
    "dev_labels = list(get_ner_bio('eng.testb'))\n",
    "dev_labels = pad_hotencode_labels(dev_labels, BIO_LABELS,max_length=max_length_sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
